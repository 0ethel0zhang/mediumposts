{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Topic Model in Python: Latent Dirichlet Allocation (LDA)\n",
    "\n",
    "In the previous article, I introduced the concept of topic modeling and walked through the code for developing your first topic model using Latent Dirichlet Allocation (LDA) method in the python using sklearn implementation.\n",
    "\n",
    "Pursuing on that understanding, in this article, I'll go a few steps deeper by outlining the framework to quantitatively evaluate topic models through the measure of topic coherence and share the code template in python using Gensim implementation to allow for end-to-end model development.\n",
    "\n",
    "### Why evaluate topic models?\n",
    "\n",
    "![img](https://tinyurl.com/y3xznjwq)\n",
    "\n",
    "We know probabilistic topic models, such as LDA, are popular tools for analysis of the text, providing both a predictive and latent topic representation of the corpus. There is a longstanding assumption that the latent space discovered by these models is meaningful and useful, and evaluating such assumptions is challenging due to its unsupervised training process. There is a no-gold standard list of topics to compare against every corpus.\n",
    "\n",
    "However, it is equally important to identify if a trained model is objectively good or bad, as well have an ability to compare different models/methods and to do so, we require an objective measure for the quality. Traditionally, and still for many practical applications, to evaluate if \"the correct thing\" has been learned about the corpus, we use implicit knowledge and \"eyeballing\" approaches. Ideally, we'd like to capture this information in a single metric that can be maximized, and compared. Let's take a look at roughly what approaches are commonly used for the evaluation:\n",
    "\n",
    "**Eye Balling Models**\n",
    "- Top N words\n",
    "- Topics / Documents\n",
    "\n",
    "**Intrinsic Evaluation Metrics**\n",
    "- Capturing model semantics\n",
    "- Topics interpretability\n",
    "\n",
    "**Human Judgements**\n",
    "- What is a topic\n",
    "\n",
    "**Extrinsic Evaluation Metrics/Evaluation at task**\n",
    "- Is model good at performing predefined tasks, such as classification\n",
    "\n",
    "Natural language is messy, ambiguous and full of subjective interpretation, and sometimes trying to cleanse ambiguity reduces the language to an unnatural form. Nevertheless, in this article, we'll explore more about topic coherence, and how we can use it to quantitatively justify the model selection.\n",
    "\n",
    "### What is Topic Coherence?\n",
    "\n",
    "Perplexity is often used as an example of an intrinsic evaluation measure. It comes from the language modeling community and aims to capture how surprised a model is of new data it has not seen before. It is measured as the normalized log-likelihood of a held-out test set.\n",
    "\n",
    "Focussing on the log-likelihood part, you can think of the perplexity metric as measuring how probable some new unseen data is given the model that was learned earlier. That is to say, how well does the model represent or reproduce the statistics of the held-out data.\n",
    "\n",
    "However, past research has shown that predictive likelihood (or equivalently, perplexity) and human judgment are often not correlated, and even sometimes slightly anti-correlated. And that served as a motivation for more work trying to model the human judgment, and thus `Topic Coherence`.\n",
    "\n",
    "The topic coherence concept combines a number of papers into one framework that allows evaluating the coherence of topics inferred by a topic model. But,\n",
    "\n",
    "#### What is topic coherence?\n",
    "Topic Coherence measures score a single topic by measuring the degree of semantic similarity between high scoring words in the topic. These measurements help distinguish between topics that are semantically interpretable topics and topics that are artifacts of statistical inference. But,\n",
    "\n",
    "#### What is coherence?\n",
    "A set of statements or facts is said to be coherent, if they support each other. Thus, a coherent fact set can be interpreted in a context that covers all or most of the facts. An example of a coherent fact set is \"the game is a team sport\", \"the game is played with a ball\", \"the game demands great physical efforts\"\n",
    "\n",
    "### Coherence Measures\n",
    "\n",
    "1. `C_v` measure is based on a sliding window, one-set segmentation of the top words and an indirect confirmation measure that uses normalized pointwise mutual information (NPMI) and the cosine similarity\n",
    "2. `C_p` is based on a sliding window, one-preceding segmentation of the top words and the confirmation measure of Fitelson's coherence\n",
    "3. `C_uci` measure is based on a sliding window and the pointwise mutual information (PMI) of all word pairs of the given top words\n",
    "4. `C_umass` is based on document cooccurrence counts, a one-preceding segmentation and a logarithmic conditional probability as confirmation measure\n",
    "5. `C_npmi` is an enhanced version of the C_uci coherence using the normalized pointwise mutual information (NPMI)\n",
    "6. `C_a` is baseed on a context window, a pairwise comparison of the top words and an indirect confirmation measure that uses normalized pointwise mutual information (NPMI) and the cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Implementation\n",
    "\n",
    "#### Loading data\n",
    "\n",
    "For this tutorial, we’ll use the dataset of papers published in NIPS conference. The NIPS conference (Neural Information Processing Systems) is one of the most prestigious yearly events in the machine learning community. The CSV data file contains information on the different NIPS papers that were published from 1987 until 2016 (29 years!). These papers discuss a wide variety of topics in machine learning, from neural networks to optimization methods, and many more.\n",
    "\n",
    "<img src=\"https://s3.amazonaws.com/assets.datacamp.com/production/project_158/img/nips_logo.png\" alt=\"The logo of NIPS (Neural Information Processing Systems)\">\n",
    "\n",
    "Let’s start by looking at the content of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>event_type</th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>Self-Organization of Associative Database and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-self-organization-of-associative-database-an...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1987</td>\n",
       "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-a-mean-field-theory-of-layer-iv-of-visual-c...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>1988</td>\n",
       "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>1994</td>\n",
       "      <td>Bayesian Query Construction for Neural Network...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000-bayesian-query-construction-for-neural-ne...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>1994</td>\n",
       "      <td>Neural Network Ensembles, Cross Validation, an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001-neural-network-ensembles-cross-validation...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  year                                              title event_type  \\\n",
       "0     1  1987  Self-Organization of Associative Database and ...        NaN   \n",
       "1    10  1987  A Mean Field Theory of Layer IV of Visual Cort...        NaN   \n",
       "2   100  1988  Storing Covariance by the Associative Long-Ter...        NaN   \n",
       "3  1000  1994  Bayesian Query Construction for Neural Network...        NaN   \n",
       "4  1001  1994  Neural Network Ensembles, Cross Validation, an...        NaN   \n",
       "\n",
       "                                            pdf_name          abstract  \\\n",
       "0  1-self-organization-of-associative-database-an...  Abstract Missing   \n",
       "1  10-a-mean-field-theory-of-layer-iv-of-visual-c...  Abstract Missing   \n",
       "2  100-storing-covariance-by-the-associative-long...  Abstract Missing   \n",
       "3  1000-bayesian-query-construction-for-neural-ne...  Abstract Missing   \n",
       "4  1001-neural-network-ensembles-cross-validation...  Abstract Missing   \n",
       "\n",
       "                                          paper_text  \n",
       "0  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...  \n",
       "1  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...  \n",
       "2  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...  \n",
       "3  Bayesian Query Construction for Neural\\nNetwor...  \n",
       "4  Neural Network Ensembles, Cross\\nValidation, a...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing modules\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir('..')\n",
    "\n",
    "# Read data into papers\n",
    "papers = pd.read_csv('./data/NIPS Papers/papers.csv')\n",
    "\n",
    "# Print head\n",
    "papers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning\n",
    "\n",
    "Since the goal of this analysis is to perform topic modeling, we will solely focus on the text data from each paper, and drop other metadata columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>Optimality of Reinforcement Learning\\nAlgorith...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3539</th>\n",
       "      <td>Dynamic Pooling and Unfolding Recursive\\nAutoe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4758</th>\n",
       "      <td>Greedy Subspace Clustering\\nDohyung Park\\nDept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3752</th>\n",
       "      <td>Semi-supervised Regression via\\nParallel Field...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>Binary to Bushy: Bayesian Hierarchical Cluster...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             paper_text\n",
       "1454  Optimality of Reinforcement Learning\\nAlgorith...\n",
       "3539  Dynamic Pooling and Unfolding Recursive\\nAutoe...\n",
       "4758  Greedy Subspace Clustering\\nDohyung Park\\nDept...\n",
       "3752  Semi-supervised Regression via\\nParallel Field...\n",
       "4599  Binary to Bushy: Bayesian Hierarchical Cluster..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the columns\n",
    "papers = papers.drop(columns=['id', 'title', 'abstract', \n",
    "                              'event_type', 'pdf_name', 'year'], axis=1)\n",
    "\n",
    "# sample only 100 papers\n",
    "papers = papers.sample(100)\n",
    "\n",
    "# Print out the first rows of papers\n",
    "papers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove punctuation/lower casing\n",
    "\n",
    "Next, let’s perform a simple preprocessing on the content of paper_text column to make them more amenable for analysis, and reliable results. To do that, we’ll use a regular expression to remove any punctuation, and then lowercase the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1454    optimality of reinforcement learning\\nalgorith...\n",
       "3539    dynamic pooling and unfolding recursive\\nautoe...\n",
       "4758    greedy subspace clustering\\ndohyung park\\ndept...\n",
       "3752    semi-supervised regression via\\nparallel field...\n",
       "4599    binary to bushy: bayesian hierarchical cluster...\n",
       "Name: paper_text_processed, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the regular expression library\n",
    "import re\n",
    "\n",
    "# Remove punctuation\n",
    "papers['paper_text_processed'] = papers['paper_text'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
    "\n",
    "# Convert the titles to lowercase\n",
    "papers['paper_text_processed'] = papers['paper_text_processed'].map(lambda x: x.lower())\n",
    "\n",
    "# Print out the first rows of papers\n",
    "papers['paper_text_processed'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize words and further clean-up text\n",
    "\n",
    "Let’s tokenize each sentence into a list of words, removing punctuations and unnecessary characters altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'optimality', u'of', u'reinforcement', u'learning', u'algorithms', u'with', u'linear', u'function', u'approximation', u'ralf', u'schoknecht', u'ilkd', u'university', u'of', u'karlsruhe', u'germany', u'ralfschoknecht', u'ilkduni', u'karlsruhede', u'abstract', u'there', u'are', u'several', u'reinforcement', u'learning', u'algorithms', u'that', u'yield', u'approximate', u'solutions']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data = papers.paper_text_processed.values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1][0][:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Bigram and Trigram Models\n",
    "\n",
    "Bigrams are two words frequently occurring together in the document. Trigrams are 3 words frequently occurring. Some examples in our example are: 'back_bumper', 'oil_leakage', 'maryland_college_park' etc.\n",
    "\n",
    "Gensim's Phrases model can build and implement the bigrams, trigrams, quadgrams and more. The two important arguments to Phrases are min_count and threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Stopwords, Make Bigrams and Lemmatize\n",
    "\n",
    "The phrase models are ready. Let’s define the functions to remove the stopwords, make trigrams and lemmatization and call them sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call the functions in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'optimality', u'reinforcement_learne', u'algorithm', u'linear', u'function', u'approximation', u'ralf', u'schoknecht', u'ilkd', u'university', u'karlsruhe', u'germany', u'ralfschoknecht', u'ilkduni', u'karlsruhede', u'abstract', u'several', u'reinforcement_learning', u'algorithm', u'yield', u'approximate', u'solution', u'problem', u'policy', u'evaluation', u'value', u'function', u'represent', u'linear', u'function']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1][0][:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data transformation: Corpus and Dictionary\n",
    "\n",
    "The two main inputs to the LDA topic model are the dictionary(id2word) and the corpus. Let’s create them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 9), (5, 1), (6, 1), (7, 8), (8, 1), (9, 2), (10, 2), (11, 1), (12, 1), (13, 14), (14, 1), (15, 1), (16, 1), (17, 55), (18, 2), (19, 1), (20, 4), (21, 1), (22, 1), (23, 2), (24, 1), (25, 3), (26, 1), (27, 1), (28, 2), (29, 5)]\n"
     ]
    }
   ],
   "source": [
    "import gensim.corpora as corpora\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1][0][:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the base topic model\n",
    "\n",
    "We have everything required to train the base LDA model. In addition to the corpus and dictionary, you need to provide the number of topics as well. Apart from that, alpha and eta are hyperparameters that affect sparsity of the topics. According to the Gensim docs, both defaults to 1.0/num_topics prior (we'll use default for the base model).\n",
    "\n",
    "chunksize controls how many documents are processed at a time in the training algorithm. Increasing chunksize will speed up training, at least as long as the chunk of documents easily fit into memory.\n",
    "\n",
    "passes controls how often we train the model on the entire corpus (set to 10). Another word for passes might be \"epochs\". iterations is somewhat technical, but essentially it controls how often we repeat a particular loop over each document. It is important to set the number of \"passes\" and \"iterations\" high enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=10, \n",
    "                                       random_state=100,\n",
    "                                       chunksize=100,\n",
    "                                       passes=10,\n",
    "                                       per_word_topics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View the topics in LDA model\n",
    "The above LDA model is built with 10 different topics where each topic is a combination of keywords and each keyword contributes a certain weightage to the topic.\n",
    "\n",
    "You can see the keywords for each topic and the weightage(importance) of each keyword using `lda_model.print_topics()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  u'0.013*\"algorithm\" + 0.010*\"state\" + 0.009*\"set\" + 0.008*\"point\" + 0.008*\"subspace\" + 0.008*\"cluster\" + 0.007*\"tree\" + 0.006*\"use\" + 0.006*\"function\" + 0.006*\"node\"'),\n",
      " (1,\n",
      "  u'0.016*\"sample\" + 0.010*\"algorithm\" + 0.009*\"distribution\" + 0.008*\"mixture\" + 0.007*\"estimator\" + 0.007*\"time\" + 0.007*\"machine\" + 0.006*\"tree\" + 0.006*\"give\" + 0.006*\"log\"'),\n",
      " (2,\n",
      "  u'0.012*\"neuron\" + 0.008*\"control\" + 0.007*\"use\" + 0.007*\"time\" + 0.006*\"optimal\" + 0.006*\"spike\" + 0.006*\"model\" + 0.006*\"reward\" + 0.005*\"system\" + 0.005*\"change\"'),\n",
      " (3,\n",
      "  u'0.010*\"function\" + 0.010*\"view\" + 0.009*\"learn\" + 0.009*\"datum\" + 0.007*\"problem\" + 0.006*\"show\" + 0.005*\"use\" + 0.005*\"approach\" + 0.005*\"result\" + 0.005*\"model\"'),\n",
      " (4,\n",
      "  u'0.011*\"model\" + 0.011*\"function\" + 0.009*\"use\" + 0.009*\"policy\" + 0.007*\"datum\" + 0.007*\"method\" + 0.007*\"matrix\" + 0.006*\"algorithm\" + 0.006*\"problem\" + 0.006*\"kernel\"'),\n",
      " (5,\n",
      "  u'0.013*\"model\" + 0.010*\"function\" + 0.008*\"set\" + 0.007*\"use\" + 0.007*\"learn\" + 0.006*\"algorithm\" + 0.006*\"datum\" + 0.005*\"tree\" + 0.005*\"method\" + 0.005*\"agent\"'),\n",
      " (6,\n",
      "  u'0.015*\"node\" + 0.015*\"message\" + 0.011*\"region\" + 0.008*\"cluster\" + 0.008*\"algorithm\" + 0.007*\"belief\" + 0.006*\"network\" + 0.006*\"set\" + 0.006*\"point\" + 0.005*\"bp\"'),\n",
      " (7,\n",
      "  u'0.013*\"model\" + 0.010*\"use\" + 0.009*\"feature\" + 0.007*\"set\" + 0.007*\"learn\" + 0.007*\"time\" + 0.006*\"algorithm\" + 0.006*\"method\" + 0.006*\"kernel\" + 0.006*\"image\"'),\n",
      " (8,\n",
      "  u'0.012*\"algorithm\" + 0.011*\"learn\" + 0.010*\"problem\" + 0.009*\"function\" + 0.008*\"set\" + 0.007*\"use\" + 0.006*\"state\" + 0.005*\"show\" + 0.005*\"datum\" + 0.005*\"label\"'),\n",
      " (9,\n",
      "  u'0.011*\"model\" + 0.007*\"set\" + 0.007*\"use\" + 0.007*\"datum\" + 0.006*\"learn\" + 0.006*\"network\" + 0.006*\"show\" + 0.005*\"algorithm\" + 0.005*\"function\" + 0.004*\"time\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Model Perplexity and Coherence Score\n",
    "\n",
    "Let's calculate the baseline coherence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Coherence Score: ', 0.30324211900240483)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('Coherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning\n",
    "\n",
    "First, let's differentiate between model hyperparameters and model parameters :\n",
    "\n",
    "- `Model hyperparameters` can be thought of as settings for a machine learning algorithm that are tuned by the data scientist before training. Examples would be the number of trees in the random forest, or in our case, number of topics K\n",
    "\n",
    "- `Model parameters` can be thought of as what the model learns during training, such as the weights for each word in a given topic.\n",
    "\n",
    "Now that we have the baseline coherence score for the default LDA model, let's perform a series of sensitivity tests to help determine the following model hyperparameters: \n",
    "- Number of Topics (K)\n",
    "- Dirichlet hyperparameter alpha: Document-Topic Density\n",
    "- Dirichlet hyperparameter beta: Word-Topic Density\n",
    "\n",
    "We'll perform these tests in sequence, one parameter at a time by keeping others constant and run them over the two difference validation corpus sets. We'll use `C_v` as our choice of metric for performance comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supporting function\n",
    "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
    "    \n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=k, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=a,\n",
    "                                           eta=b)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "    \n",
    "    return coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call the function, and iterate it over the range of topics, alpha, and beta parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 540/540 [1:55:58<00:00, 15.09s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "grid = {}\n",
    "grid['Validation_Set'] = {}\n",
    "\n",
    "# Topics range\n",
    "min_topics = 2\n",
    "max_topics = 11\n",
    "step_size = 1\n",
    "topics_range = range(min_topics, max_topics, step_size)\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = list(np.arange(0.01, 1, 0.3))\n",
    "alpha.append('symmetric')\n",
    "alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "beta = list(np.arange(0.01, 1, 0.3))\n",
    "beta.append('symmetric')\n",
    "\n",
    "# Validation sets\n",
    "num_of_docs = len(corpus)\n",
    "corpus_sets = [# gensim.utils.ClippedCorpus(corpus, num_of_docs*0.25), \n",
    "               # gensim.utils.ClippedCorpus(corpus, num_of_docs*0.5), \n",
    "               gensim.utils.ClippedCorpus(corpus, num_of_docs*0.75), \n",
    "               corpus]\n",
    "\n",
    "corpus_title = ['75% Corpus', '100% Corpus']\n",
    "\n",
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "\n",
    "# Can take a long time to run\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(total=540)\n",
    "    \n",
    "    # iterate through validation corpuses\n",
    "    for i in range(len(corpus_sets)):\n",
    "        # iterate through number of topics\n",
    "        for k in topics_range:\n",
    "            # iterate through alpha values\n",
    "            for a in alpha:\n",
    "                # iterare through beta values\n",
    "                for b in beta:\n",
    "                    # get the coherence score for the given parameters\n",
    "                    cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word, \n",
    "                                                  k=k, a=a, b=b)\n",
    "                    # Save the model results\n",
    "                    model_results['Validation_Set'].append(corpus_title[i])\n",
    "                    model_results['Topics'].append(k)\n",
    "                    model_results['Alpha'].append(a)\n",
    "                    model_results['Beta'].append(b)\n",
    "                    model_results['Coherence'].append(cv)\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "    pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model Training\n",
    "\n",
    "Based on external evaluation (Code to be added from Excel based analysis), train the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=8, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=0.01,\n",
    "                                           eta=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  u'0.006*\"algorithm\" + 0.006*\"cluster\" + 0.006*\"set\" + 0.005*\"node\" + 0.005*\"state\" + 0.004*\"clustering\" + 0.004*\"category\" + 0.003*\"network\" + 0.003*\"use\" + 0.003*\"show\"'),\n",
      " (1,\n",
      "  u'0.008*\"algorithm\" + 0.006*\"subspace\" + 0.006*\"sample\" + 0.005*\"point\" + 0.004*\"estimator\" + 0.004*\"mixture\" + 0.004*\"log\" + 0.004*\"machine\" + 0.003*\"cluster\" + 0.003*\"time\"'),\n",
      " (2,\n",
      "  u'0.006*\"spike\" + 0.004*\"control\" + 0.004*\"neuron\" + 0.003*\"system\" + 0.003*\"optimal\" + 0.003*\"segment\" + 0.003*\"vor\" + 0.003*\"dynamic\" + 0.002*\"noise\" + 0.002*\"use\"'),\n",
      " (3,\n",
      "  u'0.007*\"learn\" + 0.006*\"problem\" + 0.006*\"datum\" + 0.006*\"function\" + 0.005*\"set\" + 0.005*\"algorithm\" + 0.005*\"use\" + 0.004*\"model\" + 0.004*\"view\" + 0.004*\"give\"'),\n",
      " (4,\n",
      "  u'0.010*\"function\" + 0.008*\"problem\" + 0.007*\"algorithm\" + 0.007*\"use\" + 0.006*\"model\" + 0.006*\"set\" + 0.006*\"policy\" + 0.006*\"state\" + 0.005*\"matrix\" + 0.005*\"method\"'),\n",
      " (5,\n",
      "  u'0.012*\"model\" + 0.007*\"learn\" + 0.006*\"set\" + 0.006*\"function\" + 0.006*\"algorithm\" + 0.006*\"datum\" + 0.005*\"use\" + 0.005*\"time\" + 0.005*\"show\" + 0.005*\"tree\"'),\n",
      " (6,\n",
      "  u'0.004*\"circuit\" + 0.003*\"fpla\" + 0.003*\"plb\" + 0.002*\"chip\" + 0.002*\"primitive\" + 0.001*\"design\" + 0.001*\"learning\" + 0.001*\"interconnect\" + 0.001*\"analog\" + 0.001*\"prototype\"'),\n",
      " (7,\n",
      "  u'0.008*\"use\" + 0.007*\"model\" + 0.006*\"learn\" + 0.005*\"feature\" + 0.005*\"set\" + 0.005*\"image\" + 0.004*\"show\" + 0.004*\"algorithm\" + 0.004*\"method\" + 0.004*\"time\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python2.7/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el106241407142093200164207503242\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el106241407142093200164207503242_data = {\"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [6, 5, 8, 4, 1, 2, 3, 7], \"token.table\": {\"Topic\": [1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 1, 2, 3, 4, 7, 8, 1, 2, 3, 4, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 7, 1, 2, 3, 4, 7, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 8, 1, 2, 3, 4, 5, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 7, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 6, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 8, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 8, 1, 2, 3, 4, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 8, 1, 2, 3, 4, 1, 2, 3, 4, 7, 1, 2, 3, 4, 7, 1, 2, 3, 4, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 7, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 7, 8, 1, 2, 3, 4, 1, 2, 3, 4, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 1, 2, 3, 4, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 7, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 8, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 6, 1, 2, 3, 4, 8, 1, 2, 3, 4, 1, 2, 3, 4, 7, 1, 2, 3, 4, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 7, 1, 2, 3, 4, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 8, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 7, 1, 2, 3, 4, 7, 1, 2, 3, 4, 7, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 7, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 8, 1, 2, 3, 4, 7, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4], \"Freq\": [0.8704509735107422, 0.06695777177810669, 0.033478885889053345, 0.033478885889053345, 0.3457276523113251, 0.4268242418766022, 0.1323155164718628, 0.008536485023796558, 0.08536484837532043, 0.22345568239688873, 0.03724261373281479, 0.03724261373281479, 0.14897045493125916, 0.5213965773582458, 0.03724261373281479, 0.02460360713303089, 0.9103334546089172, 0.02460360713303089, 0.02460360713303089, 0.7809348702430725, 0.14127464592456818, 0.003924295771867037, 0.007848591543734074, 0.06278873234987259, 0.052439942955970764, 0.8390390872955322, 0.052439942955970764, 0.052439942955970764, 0.34223005175590515, 0.25988897681236267, 0.14924317598342896, 0.11407668143510818, 0.07204843312501907, 0.0608980767428875, 0.0008577193948440254, 0.0008577193948440254, 0.39882874488830566, 0.20045843720436096, 0.16913680732250214, 0.14199139177799225, 0.06055515259504318, 0.020881086587905884, 0.008352434262633324, 0.9260743260383606, 0.026459267362952232, 0.026459267362952232, 0.026459267362952232, 0.3544292449951172, 0.29535770416259766, 0.1772146224975586, 0.05907154083251953, 0.05907154083251953, 0.05907154083251953, 0.12627167999744415, 0.02525433711707592, 0.782884418964386, 0.02525433711707592, 0.02525433711707592, 0.8892534971237183, 0.04042061045765877, 0.04042061045765877, 0.04042061045765877, 0.23599429428577423, 0.28506243228912354, 0.24534060060977936, 0.16823355853557587, 0.03504865989089012, 0.028038926422595978, 0.0023365772794932127, 0.17162032425403595, 0.44514021277427673, 0.17162032425403595, 0.12871524691581726, 0.04290508106350899, 0.032178811728954315, 0.27289605140686035, 0.4879050552845001, 0.13231323659420013, 0.05375225469470024, 0.04548267647624016, 0.008269577287137508, 0.8747986555099487, 0.033646102994680405, 0.033646102994680405, 0.033646102994680405, 0.5374590158462524, 0.02756199985742569, 0.3307439982891083, 0.013780999928712845, 0.05512399971485138, 0.013780999928712845, 0.02756199985742569, 0.013780999928712845, 0.10053106397390366, 0.10053106397390366, 0.10053106397390366, 0.10053106397390366, 0.6031863689422607, 0.141472727060318, 0.141472727060318, 0.282945454120636, 0.141472727060318, 0.141472727060318, 0.141472727060318, 0.10056257992982864, 0.10056257992982864, 0.10056257992982864, 0.10056257992982864, 0.6033754944801331, 0.799183189868927, 0.032619722187519073, 0.032619722187519073, 0.11416903138160706, 0.016309861093759537, 0.8937563896179199, 0.03437524288892746, 0.03437524288892746, 0.03437524288892746, 0.0720234289765358, 0.06001952290534973, 0.8402733206748962, 0.012003904208540916, 0.022145716473460197, 0.022145716473460197, 0.022145716473460197, 0.907974362373352, 0.14332838356494904, 0.28665676712989807, 0.07166419178247452, 0.07166419178247452, 0.07166419178247452, 0.4299851655960083, 0.0350908599793911, 0.3509085774421692, 0.0350908599793911, 0.0350908599793911, 0.5614537596702576, 0.034906260669231415, 0.872656524181366, 0.034906260669231415, 0.034906260669231415, 0.3239428400993347, 0.1815730631351471, 0.29092955589294434, 0.14649644494056702, 0.026823293417692184, 0.028886623680591583, 0.002063330262899399, 0.035444214940071106, 0.035444214940071106, 0.8861053586006165, 0.035444214940071106, 0.10589105635881424, 0.10589105635881424, 0.10589105635881424, 0.10589105635881424, 0.6353463530540466, 0.040989041328430176, 0.040989041328430176, 0.8607698678970337, 0.040989041328430176, 0.06592564284801483, 0.06592564284801483, 0.06592564284801483, 0.06592564284801483, 0.7251821160316467, 0.31755611300468445, 0.22415724396705627, 0.07471908628940582, 0.09339885413646698, 0.03735954314470291, 0.24283701181411743, 0.1326906979084015, 0.1326906979084015, 0.1326906979084015, 0.1326906979084015, 0.530762791633606, 0.8772661685943604, 0.036552757024765015, 0.036552757024765015, 0.036552757024765015, 0.0802597627043724, 0.0802597627043724, 0.0802597627043724, 0.0802597627043724, 0.7223379015922546, 0.7367781400680542, 0.029869385063648224, 0.1294340044260025, 0.05973877012729645, 0.029869385063648224, 0.04677664116024971, 0.04677664116024971, 0.8419795632362366, 0.04677664116024971, 0.025737155228853226, 0.05147431045770645, 0.8750633001327515, 0.025737155228853226, 0.025737155228853226, 0.17081774771213531, 0.17081774771213531, 0.17081774771213531, 0.17081774771213531, 0.34163549542427063, 0.09326741844415665, 0.15544569492340088, 0.699505627155304, 0.015544570051133633, 0.015544570051133633, 0.015544570051133633, 0.03808252513408661, 0.8758981227874756, 0.03808252513408661, 0.03808252513408661, 0.18291249871253967, 0.18291249871253967, 0.12194166332483292, 0.06097083166241646, 0.12194166332483292, 0.24388332664966583, 0.03890945389866829, 0.07781890779733658, 0.03890945389866829, 0.7781890630722046, 0.03890945389866829, 0.03890945389866829, 0.12437431514263153, 0.12437431514263153, 0.12437431514263153, 0.12437431514263153, 0.4974972605705261, 0.10947029292583466, 0.10947029292583466, 0.10947029292583466, 0.10947029292583466, 0.5473514795303345, 0.046287357807159424, 0.023143678903579712, 0.879459798336029, 0.023143678903579712, 0.023143678903579712, 0.4387764632701874, 0.16316311061382294, 0.185212180018425, 0.1609582006931305, 0.03968832269310951, 0.008819627575576305, 0.004409813787788153, 0.04240090399980545, 0.10600226372480392, 0.22260475158691406, 0.05300113186240196, 0.5618119835853577, 0.11019141227006912, 0.02754785306751728, 0.08264356106519699, 0.7437920570373535, 0.36960944533348083, 0.007864031009376049, 0.023592092096805573, 0.2280568927526474, 0.3617454171180725, 0.007864031009376049, 0.33984532952308655, 0.0738794133067131, 0.13298295438289642, 0.05910353362560272, 0.3693970739841461, 0.02955176681280136, 0.1383185237646103, 0.1383185237646103, 0.1383185237646103, 0.1383185237646103, 0.41495558619499207, 0.12016158550977707, 0.12016158550977707, 0.12016158550977707, 0.12016158550977707, 0.12016158550977707, 0.4806463420391083, 0.8179781436920166, 0.07716774940490723, 0.046300649642944336, 0.015433549880981445, 0.015433549880981445, 0.4624640643596649, 0.08545532077550888, 0.21615168452262878, 0.12064280360937119, 0.055294618010520935, 0.015080350451171398, 0.04021426662802696, 0.14034055173397064, 0.14034055173397064, 0.14034055173397064, 0.14034055173397064, 0.5613622069358826, 0.09569693356752396, 0.09569693356752396, 0.09569693356752396, 0.09569693356752396, 0.6698785424232483, 0.09019709378480911, 0.09019709378480911, 0.09019709378480911, 0.09019709378480911, 0.6313796639442444, 0.1250876933336258, 0.2501753866672516, 0.1250876933336258, 0.1250876933336258, 0.2501753866672516, 0.868189811706543, 0.028465241193771362, 0.014232620596885681, 0.014232620596885681, 0.014232620596885681, 0.014232620596885681, 0.056930482387542725, 0.22769325971603394, 0.25909921526908875, 0.13740110397338867, 0.18058431148529053, 0.18058431148529053, 0.015702983364462852, 0.08837050944566727, 0.061859358102083206, 0.5832453966140747, 0.09720756113529205, 0.10604461282491684, 0.008837050758302212, 0.04418525472283363, 0.24097459018230438, 0.1515807807445526, 0.05830030143260956, 0.09716717153787613, 0.3264816999435425, 0.12437397986650467, 0.17823222279548645, 0.07723396271467209, 0.04752859100699425, 0.20199652016162872, 0.3505233824253082, 0.14258578419685364, 0.19949083030223846, 0.19949083030223846, 0.19949083030223846, 0.19949083030223846, 0.07381650060415268, 0.07381650060415268, 0.07381650060415268, 0.07381650060415268, 0.738165020942688, 0.05190867930650711, 0.05190867930650711, 0.05190867930650711, 0.05190867930650711, 0.7786301970481873, 0.25446954369544983, 0.025446955114603043, 0.6361739039421082, 0.03817043453454971, 0.050893910229206085, 0.0287262462079525, 0.8043348789215088, 0.0287262462079525, 0.0861787348985672, 0.0287262462079525, 0.0287262462079525, 0.8113564252853394, 0.10640740394592285, 0.03990277647972107, 0.013300925493240356, 0.013300925493240356, 0.026601850986480713, 0.27838650345802307, 0.1904749721288681, 0.31745827198028564, 0.05860768258571625, 0.043955761939287186, 0.10256344825029373, 0.009767946787178516, 0.16867215931415558, 0.08433607965707779, 0.33734431862831116, 0.08433607965707779, 0.16867215931415558, 0.08433607965707779, 0.08433607965707779, 0.08433607965707779, 0.08009561151266098, 0.08009561151266098, 0.08009561151266098, 0.08009561151266098, 0.720860481262207, 0.06370781362056732, 0.7644937634468079, 0.09556172043085098, 0.03185390681028366, 0.03185390681028366, 0.12067949026823044, 0.13165034353733063, 0.6801934838294983, 0.04388345032930374, 0.010970862582325935, 0.010970862582325935, 0.010970862582325935, 0.2916797995567322, 0.22515633702278137, 0.16886726021766663, 0.14328131079673767, 0.05628908425569534, 0.07675784081220627, 0.03582032769918442, 0.513824462890625, 0.18930375576019287, 0.05408678576350212, 0.05408678576350212, 0.16226036846637726, 0.02704339288175106, 0.19664759933948517, 0.19664759933948517, 0.19664759933948517, 0.19664759933948517, 0.19664759933948517, 0.2497245818376541, 0.29708611965179443, 0.10333430767059326, 0.28416934609413147, 0.04736155644059181, 0.008611191995441914, 0.004305595997720957, 0.03698617219924927, 0.8876681327819824, 0.03698617219924927, 0.03698617219924927, 0.100544773042202, 0.100544773042202, 0.100544773042202, 0.100544773042202, 0.6032686233520508, 0.38484543561935425, 0.0865902230143547, 0.0865902230143547, 0.3944665789604187, 0.02886340767145157, 0.019242271780967712, 0.16548828780651093, 0.44380947947502136, 0.1128329187631607, 0.075221948325634, 0.04513316601514816, 0.007522194646298885, 0.15796609222888947, 0.10893801599740982, 0.21787603199481964, 0.10893801599740982, 0.10893801599740982, 0.4357520639896393, 0.9198822975158691, 0.02920261211693287, 0.014601306058466434, 0.014601306058466434, 0.014601306058466434, 0.1411362886428833, 0.5779867172241211, 0.13441552221775055, 0.10753241181373596, 0.02688310295343399, 0.006720775738358498, 0.03434811532497406, 0.6697882413864136, 0.01717405766248703, 0.24043682217597961, 0.01717405766248703, 0.01717405766248703, 0.19996170699596405, 0.19996170699596405, 0.19996170699596405, 0.19996170699596405, 0.7477610111236572, 0.009711181744933128, 0.09711182117462158, 0.12624536454677582, 0.009711181744933128, 0.009711181744933128, 0.04535622149705887, 0.04535622149705887, 0.8617682456970215, 0.04535622149705887, 0.24033650755882263, 0.18311353027820587, 0.06866757571697235, 0.10300135612487793, 0.2632257044315338, 0.034333787858486176, 0.10300135612487793, 0.0536208413541317, 0.0536208413541317, 0.0536208413541317, 0.8043125867843628, 0.14016908407211304, 0.14016908407211304, 0.14016908407211304, 0.14016908407211304, 0.4205072522163391, 0.9011251330375671, 0.033375006169080734, 0.033375006169080734, 0.033375006169080734, 0.44825032353401184, 0.24450017511844635, 0.19356264173984528, 0.02037501521408558, 0.06112504377961159, 0.01018750760704279, 0.02037501521408558, 0.01018750760704279, 0.4357956647872925, 0.2905304431915283, 0.14526522159576416, 0.14526522159576416, 0.2391282618045807, 0.2391282618045807, 0.2391282618045807, 0.2391282618045807, 0.016541391611099243, 0.06616556644439697, 0.016541391611099243, 0.8766937255859375, 0.41570374369621277, 0.19135569036006927, 0.1484656184911728, 0.1704605370759964, 0.05168803408741951, 0.019795415922999382, 0.0021994907874614, 0.027910664677619934, 0.8931412696838379, 0.027910664677619934, 0.027910664677619934, 0.019596504047513008, 0.039193008095026016, 0.9014391899108887, 0.019596504047513008, 0.05241397023200989, 0.05241397023200989, 0.8386235237121582, 0.05241397023200989, 0.3519953191280365, 0.2273303121328354, 0.13566486537456512, 0.2273303121328354, 0.018333090469241142, 0.03299956023693085, 0.35488179326057434, 0.3184836506843567, 0.14559252560138702, 0.018199065700173378, 0.009099532850086689, 0.14559252560138702, 0.30574387311935425, 0.1411125510931015, 0.3410220146179199, 0.11759379506111145, 0.058796897530555725, 0.011759379878640175, 0.011759379878640175, 0.011759379878640175, 0.23918229341506958, 0.23918229341506958, 0.23918229341506958, 0.23918229341506958, 0.0961536318063736, 0.1442304402589798, 0.4395594596862793, 0.006868116557598114, 0.3090652525424957, 0.006868116557598114, 0.2335902601480484, 0.10617739707231522, 0.21235479414463043, 0.021235479041934013, 0.42470958828926086, 0.42898356914520264, 0.178536519408226, 0.16365846991539001, 0.1611787974834442, 0.029756085947155952, 0.0247967392206192, 0.00991869531571865, 0.3811569809913635, 0.12705232203006744, 0.06352616101503372, 0.19057849049568176, 0.12705232203006744, 0.06352616101503372, 0.06352616101503372, 0.035303179174661636, 0.3883349895477295, 0.035303179174661636, 0.035303179174661636, 0.5295476913452148, 0.14983287453651428, 0.14983287453651428, 0.14983287453651428, 0.14983287453651428, 0.44949862360954285, 0.5446720123291016, 0.06407906115055084, 0.06407906115055084, 0.03203953057527542, 0.2883557677268982, 0.20939858257770538, 0.20939858257770538, 0.31409788131713867, 0.10469929128885269, 0.10469929128885269, 0.10469929128885269, 0.18321293592453003, 0.26649153232574463, 0.19154079258441925, 0.2081965208053589, 0.024983583018183708, 0.13324576616287231, 0.22662295401096344, 0.22662295401096344, 0.22662295401096344, 0.22662295401096344, 0.027338892221450806, 0.08201667666435242, 0.8201667666435242, 0.027338892221450806, 0.2736244797706604, 0.11345405131578445, 0.10010651499032974, 0.3336883783340454, 0.1067802831530571, 0.08008521795272827, 0.1416308879852295, 0.047210294753313065, 0.047210294753313065, 0.7081544399261475, 0.047210294753313065, 0.3180641531944275, 0.1912411004304886, 0.24760690331459045, 0.11071853339672089, 0.07045724987983704, 0.05636579915881157, 0.09327290207147598, 0.09327290207147598, 0.18654580414295197, 0.04663645103573799, 0.4663645029067993, 0.04663645103573799, 0.08787209540605545, 0.06276578456163406, 0.03765946999192238, 0.6025515198707581, 0.1757441908121109, 0.012553156353533268, 0.056400105357170105, 0.056400105357170105, 0.056400105357170105, 0.056400105357170105, 0.7896015048027039, 0.021910343319177628, 0.021910343319177628, 0.9202344417572021, 0.021910343319177628, 0.1825636774301529, 0.19660703837871552, 0.4493875205516815, 0.04915175959467888, 0.028086720034480095, 0.09128183871507645, 0.6941680908203125, 0.17038671672344208, 0.056795570999383926, 0.018931856378912926, 0.03786371275782585, 0.018931856378912926, 0.05474695563316345, 0.8212043642997742, 0.05474695563316345, 0.05474695563316345, 0.17658354341983795, 0.17658354341983795, 0.38848379254341125, 0.0706334114074707, 0.1412668228149414, 0.03531670570373535, 0.8257744312286377, 0.04234740510582924, 0.04234740510582924, 0.04234740510582924, 0.04234740510582924, 0.10163305699825287, 0.025408264249563217, 0.7876561880111694, 0.025408264249563217, 0.025408264249563217, 0.025408264249563217, 0.044316843152046204, 0.044316843152046204, 0.044316843152046204, 0.8420199751853943, 0.042777080088853836, 0.042777080088853836, 0.8127645254135132, 0.042777080088853836, 0.042777080088853836, 0.3350220322608948, 0.33809560537338257, 0.14445903897285461, 0.10450228303670883, 0.012294386513531208, 0.06454552710056305, 0.003073596628382802, 0.10598492622375488, 0.23846609890460968, 0.03974434733390808, 0.05299246311187744, 0.01324811577796936, 0.5299246311187744, 0.03974434733390808, 0.14988556504249573, 0.14988556504249573, 0.14988556504249573, 0.14988556504249573, 0.4496566951274872, 0.3175521194934845, 0.19383051991462708, 0.25362929701805115, 0.16083809733390808, 0.0556747242808342, 0.014434187673032284, 0.004124053753912449, 0.5774133205413818, 0.036088332533836365, 0.036088332533836365, 0.07217666506767273, 0.07217666506767273, 0.18044166266918182, 0.04190223664045334, 0.8799470067024231, 0.04190223664045334, 0.04190223664045334, 0.3991180956363678, 0.2077043205499649, 0.2117769569158554, 0.12217901647090912, 0.028508435934782028, 0.008145267143845558, 0.024435803294181824, 0.9102244973182678, 0.017847539857029915, 0.017847539857029915, 0.017847539857029915, 0.017847539857029915, 0.017847539857029915, 0.2750777006149292, 0.03438471257686615, 0.646432638168335, 0.01375388540327549, 0.006876942701637745, 0.02750777080655098, 0.033644795417785645, 0.033644795417785645, 0.8747646808624268, 0.033644795417785645, 0.2530805468559265, 0.04668475687503815, 0.508618175983429, 0.1253117173910141, 0.058970220386981964, 0.0024570925161242485, 0.0073712775483727455, 0.26522296667099, 0.044203829020261765, 0.08840765804052353, 0.044203829020261765, 0.53044593334198, 0.09572412073612213, 0.09572412073612213, 0.09572412073612213, 0.09572412073612213, 0.6700688600540161, 0.0957069993019104, 0.0957069993019104, 0.0957069993019104, 0.0957069993019104, 0.6699489951133728, 0.03823227435350418, 0.8028777241706848, 0.07646454870700836, 0.03823227435350418, 0.25847670435905457, 0.13539256155490875, 0.07385049015283585, 0.4800281822681427, 0.024616830050945282, 0.012308415025472641, 0.22260476648807526, 0.22260476648807526, 0.22260476648807526, 0.22260476648807526, 0.22260476648807526, 0.2348063737154007, 0.2348063737154007, 0.2348063737154007, 0.2348063737154007, 0.4695611894130707, 0.18073676526546478, 0.19314026832580566, 0.0761929452419281, 0.06733330339193344, 0.0070877159014344215, 0.00531578715890646, 0.35147708654403687, 0.19845303893089294, 0.21519005298614502, 0.15302403271198273, 0.05738401412963867, 0.01912800408899784, 0.00478200102224946, 0.311207115650177, 0.17148147523403168, 0.2476954609155655, 0.08256515115499496, 0.06351165473461151, 0.10796981304883957, 0.006351165473461151, 0.2118135541677475, 0.2118135541677475, 0.2118135541677475, 0.2118135541677475, 0.2118135541677475, 0.3464171290397644, 0.2717404067516327, 0.15557655692100525, 0.16802269220352173, 0.029040958732366562, 0.026966603472828865, 0.004148708190768957, 0.2174006849527359, 0.03623344749212265, 0.03623344749212265, 0.03623344749212265, 0.6884354948997498, 0.23917552828788757, 0.23917552828788757, 0.23917552828788757, 0.23917552828788757, 0.13313481211662292, 0.13313481211662292, 0.13313481211662292, 0.13313481211662292, 0.3994044363498688, 0.34447935223579407, 0.0688958689570427, 0.2928074598312378, 0.1550157070159912, 0.017223967239260674, 0.12056777626276016, 0.3561377227306366, 0.3757338225841522, 0.11757656931877136, 0.1278006136417389, 0.011928057298064232, 0.008520041592419147, 0.0017040082020685077, 0.2391669899225235, 0.2391669899225235, 0.2391669899225235, 0.2391669899225235, 0.29389649629592896, 0.34048983454704285, 0.24013493955135345, 0.0537615530192852, 0.0071682073175907135, 0.06451386213302612, 0.0035841036587953568, 0.3471522331237793, 0.2549399137496948, 0.1790003627538681, 0.11933358013629913, 0.04339402914047241, 0.027121268212795258, 0.03254552185535431, 0.879817545413971, 0.041896071285009384, 0.041896071285009384, 0.041896071285009384, 0.35528481006622314, 0.20890136063098907, 0.20890136063098907, 0.1524827480316162, 0.032021377235651016, 0.03812068700790405, 0.0030496548861265182, 0.08360697329044342, 0.7710421085357666, 0.05573798343539238, 0.0743173137307167, 0.009289664216339588, 0.3589846193790436, 0.4345603287220001, 0.07935449481010437, 0.10580599308013916, 0.015115142799913883, 0.007557571399956942, 0.0758175328373909, 0.0758175328373909, 0.0758175328373909, 0.0758175328373909, 0.6823578476905823, 0.08243157714605331, 0.08243157714605331, 0.08243157714605331, 0.08243157714605331, 0.6594526171684265, 0.14028631150722504, 0.14028631150722504, 0.14028631150722504, 0.14028631150722504, 0.14028631150722504, 0.4208589494228363, 0.057260215282440186, 0.8016430139541626, 0.057260215282440186, 0.057260215282440186, 0.4561418890953064, 0.1140354722738266, 0.1140354722738266, 0.1140354722738266, 0.1140354722738266, 0.8802561163902283, 0.04191695898771286, 0.04191695898771286, 0.04191695898771286, 0.1332681030035019, 0.1332681030035019, 0.1332681030035019, 0.1332681030035019, 0.5330724120140076, 0.17073385417461395, 0.17073385417461395, 0.17073385417461395, 0.17073385417461395, 0.3414677083492279, 0.06399622559547424, 0.1279924511909485, 0.06399622559547424, 0.06399622559547424, 0.6399622559547424, 0.042110148817300797, 0.042110148817300797, 0.042110148817300797, 0.042110148817300797, 0.8422030210494995, 0.7675358057022095, 0.038376789540052414, 0.07675357908010483, 0.038376789540052414, 0.07675357908010483, 0.020074831321835518, 0.1806734800338745, 0.7628436088562012, 0.020074831321835518, 0.0599539652466774, 0.1199079304933548, 0.0599539652466774, 0.7194475531578064, 0.23468568921089172, 0.23468568921089172, 0.23468568921089172, 0.23468568921089172, 0.04860199987888336, 0.826233983039856, 0.04860199987888336, 0.04860199987888336, 0.02213222160935402, 0.8852888941764832, 0.04426444321870804, 0.02213222160935402, 0.2927296459674835, 0.09757654368877411, 0.09757654368877411, 0.09757654368877411, 0.39030617475509644, 0.08665259182453156, 0.08665259182453156, 0.08665259182453156, 0.08665259182453156, 0.6932207345962524, 0.3552408814430237, 0.09554754942655563, 0.44833850860595703, 0.024499371647834778, 0.06369836628437042, 0.009799748659133911, 0.002449937164783478, 0.5360333323478699, 0.2207196056842804, 0.07882843166589737, 0.03153137490153313, 0.07882843166589737, 0.015765687450766563, 0.015765687450766563, 0.015765687450766563, 0.26549893617630005, 0.26549893617630005, 0.13274946808815002, 0.09292463213205338, 0.18584926426410675, 0.039824843406677246, 0.013274947181344032, 0.013274947181344032, 0.09228077530860901, 0.018456153571605682, 0.11073692888021469, 0.11073692888021469, 0.6459653973579407, 0.018456153571605682, 0.04055541381239891, 0.8516637086868286, 0.04055541381239891, 0.04055541381239891, 0.22323226928710938, 0.055808067321777344, 0.6138887405395508, 0.07175323367118835, 0.031890325248241425, 0.007972581312060356, 0.007972581312060356, 0.05035126954317093, 0.05035126954317093, 0.8056203126907349, 0.05035126954317093, 0.15360498428344727, 0.038401246070861816, 0.038401246070861816, 0.6912224292755127, 0.07680249214172363, 0.5982256531715393, 0.1455143541097641, 0.10509370267391205, 0.11587253957986832, 0.013473550789058208, 0.005389420315623283, 0.018862972036004066, 0.0026947101578116417, 0.047568339854478836, 0.047568339854478836, 0.047568339854478836, 0.047568339854478836, 0.8086617588996887, 0.8595684170722961, 0.06203071027994156, 0.01772306114435196, 0.00886153057217598, 0.0443076491355896, 0.00886153057217598, 0.40084144473075867, 0.13361380994319916, 0.13361380994319916, 0.13361380994319916, 0.13361380994319916, 0.13361380994319916, 0.07194460183382034, 0.07194460183382034, 0.07194460183382034, 0.7913906574249268, 0.461638480424881, 0.15387949347496033, 0.15387949347496033, 0.15387949347496033, 0.15387949347496033, 0.5474863648414612, 0.04379890859127045, 0.021899454295635223, 0.04379890859127045, 0.21899454295635223, 0.021899454295635223, 0.13139672577381134, 0.23057760298252106, 0.23057760298252106, 0.23057760298252106, 0.23057760298252106, 0.10481800884008408, 0.10481800884008408, 0.10481800884008408, 0.10481800884008408, 0.6289080381393433, 0.141919806599617, 0.3955637216567993, 0.3170548975467682, 0.12380238622426987, 0.006039140745997429, 0.012078281491994858, 0.0030195703729987144, 0.08486547321081161, 0.16973094642162323, 0.08486547321081161, 0.08486547321081161, 0.5940583348274231, 0.10026293992996216, 0.10026293992996216, 0.10026293992996216, 0.10026293992996216, 0.601577639579773, 0.08265410363674164, 0.08265410363674164, 0.08265410363674164, 0.08265410363674164, 0.6612328290939331, 0.10589331388473511, 0.10589331388473511, 0.10589331388473511, 0.10589331388473511, 0.6353598833084106, 0.8583290576934814, 0.0451752133667469, 0.0451752133667469, 0.0451752133667469, 0.2654867470264435, 0.20081688463687897, 0.12253233790397644, 0.2722940742969513, 0.11912866681814194, 0.013614704832434654, 0.0034036762081086636, 0.45188990235328674, 0.18806979060173035, 0.16194897890090942, 0.10970737785100937, 0.05224160850048065, 0.02873288467526436, 0.005224160850048065, 0.43291524052619934, 0.12704059481620789, 0.21694624423980713, 0.17883406579494476, 0.02247641235589981, 0.019544705748558044, 0.0009772352641448379, 0.0009772352641448379, 0.4600764513015747, 0.17853713035583496, 0.15106987953186035, 0.157936692237854, 0.030900655314326286, 0.013733625411987305, 0.003433406352996826, 0.003433406352996826, 0.2788994610309601, 0.3082572817802429, 0.08807351440191269, 0.16146810352802277, 0.03669729828834534, 0.12477081269025803, 0.31676340103149414, 0.33314770460128784, 0.16657385230064392, 0.12561307847499847, 0.016384314745664597, 0.03823006525635719, 0.002730719046667218, 0.060356736183166504, 0.060356736183166504, 0.060356736183166504, 0.7846375703811646, 0.03482455387711525, 0.03482455387711525, 0.03482455387711525, 0.8357892632484436, 0.03482455387711525, 0.6981410980224609, 0.09677203744649887, 0.08294746279716492, 0.05529830604791641, 0.03456144034862518, 0.027649153023958206, 0.3101637661457062, 0.31533315777778625, 0.21194523572921753, 0.0542786568403244, 0.010338791646063328, 0.09563382714986801, 0.16723555326461792, 0.2580205500125885, 0.210238978266716, 0.33924925327301025, 0.014334475621581078, 0.009556316770613194, 0.05722777917981148, 0.8011888861656189, 0.05722777917981148, 0.05722777917981148, 0.10485578328371048, 0.10485578328371048, 0.10485578328371048, 0.10485578328371048, 0.10485578328371048, 0.6291347146034241, 0.06636041402816772, 0.06636041402816772, 0.06636041402816772, 0.06636041402816772, 0.729964554309845, 0.08872540295124054, 0.08872540295124054, 0.08872540295124054, 0.08872540295124054, 0.621077835559845, 0.27318069338798523, 0.27318069338798523, 0.14205396175384521, 0.15662360191345215, 0.01821204647421837, 0.12748432159423828, 0.007284818682819605, 0.0036424093414098024, 0.8592644333839417, 0.04522444307804108, 0.04522444307804108, 0.04522444307804108, 0.11780688911676407, 0.07068413496017456, 0.11780688911676407, 0.612595796585083, 0.023561377078294754, 0.04712275415658951, 0.13319814205169678, 0.40742960572242737, 0.031340740621089935, 0.4152647852897644, 0.007835185155272484, 0.007835185155272484, 0.05200352519750595, 0.05200352519750595, 0.05200352519750595, 0.8320564031600952, 0.25621578097343445, 0.08540526032447815, 0.08540526032447815, 0.08540526032447815, 0.5124315619468689, 0.18546871840953827, 0.4367489218711853, 0.17350299656391144, 0.1555544137954712, 0.00598286185413599, 0.041880033910274506, 0.0019942873623222113, 0.03964166343212128, 0.03964166343212128, 0.03964166343212128, 0.8721166253089905, 0.49993467330932617, 0.20489126443862915, 0.13386228680610657, 0.10381156951189041, 0.03824636712670326, 0.01912318356335163, 0.002731883432716131, 0.8693740963935852, 0.04346870630979538, 0.04346870630979538, 0.04346870630979538, 0.15069781243801117, 0.8100007176399231, 0.018837226554751396, 0.018837226554751396, 0.2842455804347992, 0.31849205493927, 0.17123228311538696, 0.09589008241891861, 0.03082181140780449, 0.09246543794870377, 0.003424645634368062, 0.03345024585723877, 0.11707586795091629, 0.7191802859306335, 0.050175368785858154, 0.016725122928619385, 0.016725122928619385, 0.03345024585723877, 0.8420905470848083, 0.04534333571791649, 0.032388098537921906, 0.019432857632637024, 0.019432857632637024, 0.03886571526527405, 0.017076591029763222, 0.3073786199092865, 0.2390722632408142, 0.017076591029763222, 0.40983816981315613, 0.017076591029763222, 0.31080055236816406, 0.3195967674255371, 0.23749852180480957, 0.07770013809204102, 0.03958308696746826, 0.013194362632930279, 0.0014660402666777372, 0.08166921883821487, 0.16333843767642975, 0.04083460941910744, 0.5716845393180847, 0.10208652168512344, 0.04083460941910744, 0.16323328018188477, 0.16323328018188477, 0.16323328018188477, 0.16323328018188477, 0.32646656036376953, 0.03764566034078598, 0.03764566034078598, 0.03764566034078598, 0.8658501505851746, 0.03501005843281746, 0.03501005843281746, 0.03501005843281746, 0.8752514719963074, 0.04071364179253578, 0.04071364179253578, 0.04071364179253578, 0.8549864888191223, 0.09117540717124939, 0.09117540717124939, 0.09117540717124939, 0.09117540717124939, 0.6382278800010681, 0.3851315677165985, 0.12035360932350159, 0.10430646687746048, 0.06418859213590622, 0.008023574016988277, 0.31291937828063965, 0.03975662216544151, 0.03975662216544151, 0.8746457099914551, 0.03975662216544151, 0.5329007506370544, 0.17450150847434998, 0.1932939738035202, 0.07382755726575851, 0.01812130957841873, 0.0040269577875733376, 0.0026846386026591063, 0.947377622127533, 0.014139964245259762, 0.014139964245259762, 0.014139964245259762, 0.14040371775627136, 0.14040371775627136, 0.14040371775627136, 0.14040371775627136, 0.14040371775627136, 0.4212111532688141, 0.23845897614955902, 0.059614744037389755, 0.059614744037389755, 0.059614744037389755, 0.11922948807477951, 0.417303204536438, 0.15103308856487274, 0.05034436285495758, 0.05034436285495758, 0.10068872570991516, 0.20137745141983032, 0.45309925079345703, 0.06966937333345413, 0.06966937333345413, 0.06966937333345413, 0.27867749333381653, 0.48768559098243713, 0.038685593754053116, 0.038685593754053116, 0.038685593754053116, 0.8510830402374268, 0.038685593754053116, 0.3002696633338928, 0.0750674158334732, 0.0750674158334732, 0.0750674158334732, 0.1501348316669464, 0.37533706426620483, 0.3074244558811188, 0.0768561139702797, 0.0768561139702797, 0.03842805698513985, 0.03842805698513985, 0.4227086305618286, 0.03842805698513985, 0.32269197702407837, 0.08067299425601959, 0.040336497128009796, 0.12100948393344879, 0.040336497128009796, 0.32269197702407837, 0.040336497128009796, 0.499239444732666, 0.18393032252788544, 0.1899939626455307, 0.016169698908925056, 0.09701819717884064, 0.002021212363615632, 0.010106061585247517, 0.02190336585044861, 0.02190336585044861, 0.9199413657188416, 0.02190336585044861, 0.8423831462860107, 0.00427605677396059, 0.012828170321881771, 0.00427605677396059, 0.04703662544488907, 0.08552113175392151, 0.23912419378757477, 0.23912419378757477, 0.23912419378757477, 0.23912419378757477, 0.053973954170942307, 0.053973954170942307, 0.053973954170942307, 0.053973954170942307, 0.8096093535423279, 0.3699101209640503, 0.11924734711647034, 0.17278696596622467, 0.14845077693462372, 0.18495506048202515, 0.0024336192291229963, 0.3190920650959015, 0.20551691949367523, 0.36235877871513367, 0.043266721069812775, 0.005408340133726597, 0.06490008533000946, 0.02920261025428772, 0.9052808880805969, 0.02920261025428772, 0.02920261025428772, 0.06296403706073761, 0.818532407283783, 0.06296403706073761, 0.06296403706073761, 0.06267788261175156, 0.06267788261175156, 0.06267788261175156, 0.06267788261175156, 0.06267788261175156, 0.7521345615386963, 0.4509206712245941, 0.2237902581691742, 0.18871864676475525, 0.08183375000953674, 0.030061377212405205, 0.023381071165204048, 0.0016700765118002892, 0.3715705871582031, 0.06708913296461105, 0.38189199566841125, 0.025803513824939728, 0.14449967443943024, 0.005160702392458916, 0.8788791298866272, 0.036619964987039566, 0.036619964987039566, 0.036619964987039566, 0.25732892751693726, 0.4796811044216156, 0.10742858052253723, 0.08994020521640778, 0.007495017256587744, 0.01998671144247055, 0.037475086748600006, 0.1034298986196518, 0.40222740173339844, 0.011492211371660233, 0.04596884548664093, 0.4252118170261383, 0.011492211371660233, 0.25259655714035034, 0.46309366822242737, 0.09823198616504669, 0.14968684315681458, 0.018710855394601822, 0.014033141545951366, 0.09247344732284546, 0.09247344732284546, 0.09247344732284546, 0.09247344732284546, 0.09247344732284546, 0.5548406839370728, 0.9036989212036133, 0.02915157936513424, 0.02915157936513424, 0.02915157936513424, 0.2558814585208893, 0.17058764398097992, 0.08529382199048996, 0.08529382199048996, 0.4264691174030304, 0.023605281487107277, 0.023605281487107277, 0.8970007300376892, 0.023605281487107277, 0.023605281487107277, 0.04533058777451515, 0.04533058777451515, 0.04533058777451515, 0.04533058777451515, 0.8159505724906921, 0.9306882619857788, 0.021152006462216377, 0.021152006462216377, 0.021152006462216377, 0.34026864171028137, 0.17013432085514069, 0.14886753261089325, 0.10633394867181778, 0.0638003721833229, 0.021266790106892586, 0.17013432085514069, 0.8722052574157715, 0.03007604368031025, 0.03007604368031025, 0.03007604368031025, 0.2542482614517212, 0.2542482614517212, 0.05084965378046036, 0.05084965378046036, 0.3559475839138031, 0.059197042137384415, 0.059197042137384415, 0.7991600632667542, 0.029598521068692207, 0.029598521068692207, 0.059197042137384415, 0.10488757491111755, 0.10488757491111755, 0.10488757491111755, 0.10488757491111755, 0.6293254494667053, 0.10480555146932602, 0.10480555146932602, 0.10480555146932602, 0.10480555146932602, 0.6288332939147949, 0.10036223381757736, 0.10036223381757736, 0.10036223381757736, 0.10036223381757736, 0.602173388004303, 0.8466514348983765, 0.045356325805187225, 0.045356325805187225, 0.015118775889277458, 0.030237551778554916, 0.14450058341026306, 0.14450058341026306, 0.14450058341026306, 0.14450058341026306, 0.4335017502307892, 0.1562018096446991, 0.1562018096446991, 0.1562018096446991, 0.1562018096446991, 0.4686054289340973, 0.3054942488670349, 0.2760762870311737, 0.14482690393924713, 0.08599098026752472, 0.0905168205499649, 0.09504266083240509, 0.006788761354982853, 0.06943008303642273, 0.8989368677139282, 0.007308430038392544, 0.014616860076785088, 0.003654215019196272, 0.003654215019196272, 0.04002055898308754, 0.8004111647605896, 0.04002055898308754, 0.08004111796617508, 0.04002055898308754, 0.04002055898308754, 0.36596837639808655, 0.09149209409952164, 0.09149209409952164, 0.09149209409952164, 0.36596837639808655, 0.0580192431807518, 0.0580192431807518, 0.0580192431807518, 0.8122694492340088, 0.274190217256546, 0.2207765430212021, 0.17448468506336212, 0.2991166114807129, 0.0071218241937458515, 0.010682735592126846, 0.010682735592126846, 0.11100658029317856, 0.6845405697822571, 0.12950767576694489, 0.018501097336411476, 0.03700219467282295, 0.018501097336411476, 0.018501097336411476, 0.068632110953331, 0.068632110953331, 0.068632110953331, 0.7549532055854797, 0.07180634886026382, 0.07180634886026382, 0.07180634886026382, 0.718063473701477, 0.07480078935623169, 0.07480078935623169, 0.5236055254936218, 0.07480078935623169, 0.14960157871246338, 0.5374855399131775, 0.23942536115646362, 0.09039529412984848, 0.06840724498033524, 0.03420362249016762, 0.02931739203631878, 0.2168920785188675, 0.4194045662879944, 0.13780435919761658, 0.19891759753227234, 0.008388091810047626, 0.014379585161805153, 0.0035948962904512882, 0.3554636538028717, 0.2771964371204376, 0.3000243604183197, 0.022827941924333572, 0.03261134400963783, 0.009783403016626835, 0.0032611344940960407, 0.0692666545510292, 0.7446165084838867, 0.0346333272755146, 0.12121664732694626, 0.0173166636377573, 0.9140282273292542, 0.025389673188328743, 0.025389673188328743, 0.012694836594164371, 0.012694836594164371, 0.8049176931381226, 0.04024588316679001, 0.04024588316679001, 0.04024588316679001, 0.04024588316679001, 0.04660707339644432, 0.8389273285865784, 0.04660707339644432, 0.04660707339644432, 0.12085665017366409, 0.12085665017366409, 0.12085665017366409, 0.12085665017366409, 0.48342660069465637, 0.051140155643224716, 0.051140155643224716, 0.051140155643224716, 0.051140155643224716, 0.8182424902915955, 0.04683748260140419, 0.09367496520280838, 0.04683748260140419, 0.7962371706962585, 0.06868214160203934, 0.06868214160203934, 0.06868214160203934, 0.7555035948753357, 0.13882772624492645, 0.13882772624492645, 0.13882772624492645, 0.13882772624492645, 0.41648316383361816, 0.0686880499124527, 0.0686880499124527, 0.0686880499124527, 0.7555685043334961, 0.0949983075261116, 0.040713559836149216, 0.013571186922490597, 0.40713560581207275, 0.42070677876472473, 0.013571186922490597, 0.039785489439964294, 0.039785489439964294, 0.8752807378768921, 0.039785489439964294, 0.403293251991272, 0.41630271077156067, 0.06938378512859344, 0.03902838006615639, 0.021682433784008026, 0.04336486756801605, 0.00433648657053709, 0.05243391916155815, 0.8389427065849304, 0.05243391916155815, 0.05243391916155815, 0.2822677195072174, 0.17300279438495636, 0.018210820853710175, 0.47348132729530334, 0.027316231280565262, 0.018210820853710175, 0.23058828711509705, 0.23058828711509705, 0.23058828711509705, 0.23058828711509705, 0.5321224331855774, 0.14367304742336273, 0.19156406819820404, 0.08513958752155304, 0.01064244844019413, 0.029266733676195145, 0.00798183586448431, 0.15626275539398193, 0.15626275539398193, 0.15626275539398193, 0.15626275539398193, 0.4687882661819458, 0.20534265041351318, 0.20534265041351318, 0.20534265041351318, 0.20534265041351318, 0.20534265041351318, 0.07981879264116287, 0.06984143704175949, 0.8181425929069519, 0.009977349080145359, 0.009977349080145359, 0.0569780170917511, 0.0569780170917511, 0.7976922392845154, 0.0569780170917511, 0.048707008361816406, 0.048707008361816406, 0.048707008361816406, 0.7793121337890625, 0.048707008361816406, 0.156062513589859, 0.156062513589859, 0.156062513589859, 0.156062513589859, 0.468187540769577, 0.3884051740169525, 0.20597244799137115, 0.235397070646286, 0.01765478029847145, 0.14712317287921906, 0.00588492676615715, 0.3405955135822296, 0.11353184282779694, 0.11353184282779694, 0.11353184282779694, 0.3405955135822296, 0.022855576127767563, 0.8456563353538513, 0.022855576127767563, 0.06856673210859299, 0.022855576127767563, 0.12093506008386612, 0.04031168669462204, 0.04031168669462204, 0.7659220695495605, 0.04031168669462204, 0.28474465012550354, 0.055832285434007645, 0.468991219997406, 0.16749686002731323, 0.011166457086801529, 0.011166457086801529, 0.09924084693193436, 0.09924084693193436, 0.09924084693193436, 0.09924084693193436, 0.5954450964927673, 0.4037206172943115, 0.2141600400209427, 0.17653733491897583, 0.13312651216983795, 0.04051676392555237, 0.023152437061071396, 0.008682163432240486, 0.8760674595832825, 0.08760674297809601, 0.010950842872262001, 0.010950842872262001, 0.010950842872262001, 0.010950842872262001, 0.0766628161072731, 0.0766628161072731, 0.0766628161072731, 0.0766628161072731, 0.6133025288581848, 0.0766628161072731, 0.13142180442810059, 0.13142180442810059, 0.13142180442810059, 0.13142180442810059, 0.5256872177124023, 0.31355491280555725, 0.27508190274238586, 0.1846703737974167, 0.10964803397655487, 0.009618248790502548, 0.10580073297023773, 0.0019236498046666384, 0.09129838645458221, 0.09129838645458221, 0.09129838645458221, 0.09129838645458221, 0.6390886902809143, 0.05035059526562691, 0.8056095242500305, 0.05035059526562691, 0.05035059526562691, 0.14866036176681519, 0.14866036176681519, 0.14866036176681519, 0.14866036176681519, 0.44598108530044556, 0.26451602578163147, 0.06412509828805923, 0.20039093494415283, 0.36871930956840515, 0.08817201107740402, 0.3553278148174286, 0.2331838756799698, 0.10548794269561768, 0.07772795855998993, 0.22207987308502197, 0.005551997106522322, 0.37491321563720703, 0.0576789565384388, 0.0576789565384388, 0.0288394782692194, 0.0576789565384388, 0.40375271439552307, 0.0443103164434433, 0.0443103164434433, 0.0443103164434433, 0.8418959975242615, 0.4658156633377075, 0.04658156633377075, 0.0931631326675415, 0.04658156633377075, 0.04658156633377075, 0.2794893980026245, 0.02234133705496788, 0.02234133705496788, 0.9159948229789734, 0.02234133705496788, 0.2503252923488617, 0.30227962136268616, 0.36840328574180603, 0.04723118990659714, 0.018892476335167885, 0.004723119083791971, 0.004723119083791971, 0.3946980834007263, 0.2242395579814911, 0.16954699158668518, 0.12123521417379379, 0.07383497804403305, 0.014584687538444996, 0.0018230859423056245, 0.7432056069374084, 0.041289202868938446, 0.17341464757919312, 0.01651567965745926, 0.024773521348834038, 0.23480530083179474, 0.23480530083179474, 0.23480530083179474, 0.23480530083179474, 0.40524357557296753, 0.17332707345485687, 0.2172691375017166, 0.11717886477708817, 0.057368818670511246, 0.026853488758206367, 0.0024412262719124556, 0.21557219326496124, 0.21557219326496124, 0.21557219326496124, 0.21557219326496124, 0.21557219326496124, 0.048393070697784424, 0.8226822018623352, 0.048393070697784424, 0.048393070697784424, 0.03125990182161331, 0.03125990182161331, 0.9065371155738831, 0.03125990182161331, 0.09155093878507614, 0.030516980215907097, 0.7934414744377136, 0.061033960431814194, 0.30340689420700073, 0.45980218052864075, 0.08132556080818176, 0.09070927649736404, 0.01251162402331829, 0.03753487393260002, 0.01563953049480915, 0.21078628301620483, 0.32917308807373047, 0.2281111776828766, 0.1703615039587021, 0.04331224784255028, 0.0173249002546072, 0.0028874832205474377, 0.15309131145477295, 0.11481847614049911, 0.191364124417305, 0.07654565572738647, 0.03827282786369324, 0.45927390456199646, 0.07562512904405594, 0.07562512904405594, 0.07562512904405594, 0.7562512755393982, 0.028363514691591263, 0.11345405876636505, 0.028363514691591263, 0.7090878486633301, 0.08509054780006409, 0.06435608118772507, 0.06435608118772507, 0.06435608118772507, 0.06435608118772507, 0.7722730040550232, 0.42458832263946533, 0.01147536002099514, 0.08032751828432083, 0.10327824205160141, 0.01147536002099514, 0.3672115206718445, 0.13730548322200775, 0.13730548322200775, 0.13730548322200775, 0.13730548322200775, 0.41191643476486206, 0.5825287699699402, 0.034266397356987, 0.068532794713974, 0.1027991995215416, 0.1713320016860962, 0.14085282385349274, 0.14085282385349274, 0.14085282385349274, 0.14085282385349274, 0.422558456659317, 0.13580535352230072, 0.13580535352230072, 0.13580535352230072, 0.13580535352230072, 0.40741604566574097, 0.08990521728992462, 0.08990521728992462, 0.08990521728992462, 0.08990521728992462, 0.08990521728992462, 0.4495261013507843, 0.10061824321746826, 0.10061824321746826, 0.10061824321746826, 0.10061824321746826, 0.10061824321746826, 0.6037094593048096, 0.05254436656832695, 0.7881655097007751, 0.05254436656832695, 0.05254436656832695, 0.11865987628698349, 0.11865987628698349, 0.11865987628698349, 0.11865987628698349, 0.593299388885498, 0.41492903232574463, 0.37891632318496704, 0.0782884955406189, 0.01409192942082882, 0.10334081202745438, 0.006263079587370157, 0.00469730980694294, 0.29761457443237305, 0.07440364360809326, 0.07440364360809326, 0.07440364360809326, 0.5208255052566528, 0.5146589875221252, 0.1639041304588318, 0.1639041304588318, 0.07211782038211823, 0.01639041304588318, 0.06556165218353271, 0.03696233406662941, 0.8870960474014282, 0.03696233406662941, 0.03696233406662941, 0.2884792983531952, 0.5345351696014404, 0.11030090600252151, 0.05090811103582382, 0.008484684862196445, 0.008484684862196445, 0.008484684862196445, 0.5039522051811218, 0.11911597102880478, 0.1374415010213852, 0.1649298071861267, 0.061085112392902374, 0.009162766858935356, 0.022184288129210472, 0.8873715400695801, 0.022184288129210472, 0.022184288129210472, 0.022184288129210472, 0.05722643435001373, 0.8011701107025146, 0.05722643435001373, 0.05722643435001373, 0.021298648789525032, 0.13844121992588043, 0.10649324208498001, 0.09584391862154007, 0.021298648789525032, 0.6176608204841614, 0.11685920506715775, 0.03895306959748268, 0.15581227838993073, 0.03895306959748268, 0.1947653442621231, 0.4284837543964386, 0.03198755532503128, 0.03198755532503128, 0.8956515192985535, 0.03198755532503128, 0.0635702833533287, 0.0635702833533287, 0.0635702833533287, 0.7628433704376221, 0.0635702833533287, 0.07240799069404602, 0.5309919714927673, 0.16895198822021484, 0.16090665757656097, 0.008045332506299019, 0.032181330025196075, 0.024135997518897057, 0.8652701377868652, 0.0346108041703701, 0.0346108041703701, 0.0346108041703701, 0.34102529287338257, 0.2488563060760498, 0.19355490803718567, 0.07987979799509048, 0.07066290080547333, 0.01843379996716976, 0.0491567999124527, 0.0030722999945282936, 0.6661635041236877, 0.06344413757324219, 0.15861035883426666, 0.04758310690522194, 0.04758310690522194, 0.010574023239314556, 0.30623123049736023, 0.2348763793706894, 0.17244088649749756, 0.21109142899513245, 0.03567742556333542, 0.008919356390833855, 0.029731187969446182, 0.09776729345321655, 0.09776729345321655, 0.09776729345321655, 0.09776729345321655, 0.5866037607192993, 0.09778209030628204, 0.09778209030628204, 0.09778209030628204, 0.09778209030628204, 0.5866925120353699, 0.9459379315376282, 0.015257063321769238, 0.015257063321769238, 0.015257063321769238, 0.015257063321769238, 0.4223637580871582, 0.2051481157541275, 0.12067536264657974, 0.2202325314283371, 0.012067535892128944, 0.006033767946064472, 0.009050652384757996, 0.8796231150627136, 0.041886813938617706, 0.041886813938617706, 0.041886813938617706, 0.07917427271604538, 0.03958713635802269, 0.831329882144928, 0.03958713635802269, 0.48360878229141235, 0.17076581716537476, 0.21721410751342773, 0.046448301523923874, 0.031420908868312836, 0.04371604695916176, 0.008196759037673473, 0.08615301549434662, 0.08615301549434662, 0.08615301549434662, 0.08615301549434662, 0.689224123954773, 0.784468948841095, 0.013296084478497505, 0.013296084478497505, 0.15955300629138947, 0.013296084478497505, 0.013296084478497505, 0.03641533479094505, 0.03641533479094505, 0.8739680647850037, 0.03641533479094505, 0.4407292306423187, 0.1082029864192009, 0.23751875758171082, 0.142511248588562, 0.03694736212491989, 0.021112777292728424, 0.010556388646364212, 0.026971125975251198, 0.026971125975251198, 0.8630760312080383, 0.053942251950502396, 0.15392524003982544, 0.06157009303569794, 0.6772710084915161, 0.015392523258924484, 0.015392523258924484, 0.015392523258924484, 0.06157009303569794, 0.2153085321187973, 0.2153085321187973, 0.2153085321187973, 0.2153085321187973, 0.2153085321187973, 0.7613811492919922, 0.06740095466375351, 0.05741562694311142, 0.034948643296957016, 0.03994130715727806, 0.03744497522711754, 0.9303827285766602, 0.01789197511970997, 0.01789197511970997, 0.01789197511970997, 0.8976293206214905, 0.029920978471636772, 0.029920978471636772, 0.029920978471636772, 0.8593101501464844, 0.03905954957008362, 0.03905954957008362, 0.03905954957008362, 0.11443126201629639, 0.11443126201629639, 0.11443126201629639, 0.11443126201629639, 0.11443126201629639, 0.5721563100814819, 0.030627774074673653, 0.8882054090499878, 0.030627774074673653, 0.030627774074673653, 0.05698038637638092, 0.05698038637638092, 0.7977254390716553, 0.05698038637638092, 0.680172860622406, 0.08081261813640594, 0.15489085018634796, 0.0471406914293766, 0.013468769378960133, 0.006734384689480066, 0.3066057562828064, 0.24528460204601288, 0.2699834108352661, 0.1064603328704834, 0.04088076949119568, 0.02044038474559784, 0.00936850905418396, 0.07437743991613388, 0.4016381800174713, 0.029750976711511612, 0.04462646320462227, 0.4165136516094208, 0.04462646320462227, 0.40737655758857727, 0.26620644330978394, 0.19562141597270966, 0.08268533647060394, 0.034284163266420364, 0.01411700900644064, 0.0020167154725641012, 0.20494984090328217, 0.45259755849838257, 0.15371237695217133, 0.03415830805897713, 0.017079154029488564, 0.15371237695217133, 0.22552064061164856, 0.20626887679100037, 0.3080281913280487, 0.2007683664560318, 0.019251761958003044, 0.0357532724738121, 0.005500503350049257, 0.14899852871894836, 0.14899852871894836, 0.14899852871894836, 0.14899852871894836, 0.4469955861568451, 0.4450690448284149, 0.20176462829113007, 0.20176462829113007, 0.005934253800660372, 0.005934253800660372, 0.14242209494113922, 0.0873722955584526, 0.1397956758737564, 0.6815038919448853, 0.052423376590013504, 0.01747445948421955, 0.01747445948421955, 0.2640862464904785, 0.08450759947299957, 0.05809897556900978, 0.570426344871521, 0.010563449934124947, 0.005281724967062473, 0.005281724967062473, 0.02839208021759987, 0.02839208021759987, 0.02839208021759987, 0.9085465669631958, 0.03971480578184128, 0.03971480578184128, 0.8737257122993469, 0.03971480578184128, 0.20544207096099854, 0.20544207096099854, 0.20544207096099854, 0.20544207096099854, 0.20544207096099854, 0.05755695328116417, 0.05755695328116417, 0.05755695328116417, 0.05755695328116417, 0.7482403516769409, 0.01844272017478943, 0.129099041223526, 0.8114796280860901, 0.01844272017478943, 0.06566338241100311, 0.06566338241100311, 0.06566338241100311, 0.7879605293273926, 0.48315131664276123, 0.08885541558265686, 0.2582360506057739, 0.08607868105173111, 0.05553463473916054, 0.019437121227383614, 0.00833019521087408, 0.1821925789117813, 0.26027512550354004, 0.1171238049864769, 0.32534390687942505, 0.07157565653324127, 0.039041269570589066, 0.04141102731227875, 0.0828220546245575, 0.04141102731227875, 0.786809504032135, 0.045214928686618805, 0.045214928686618805, 0.8590836524963379, 0.045214928686618805], \"Term\": [\"absorb\", \"absorb\", \"absorb\", \"absorb\", \"action\", \"action\", \"action\", \"action\", \"action\", \"adaptation\", \"adaptation\", \"adaptation\", \"adaptation\", \"adaptation\", \"adaptation\", \"advi\", \"advi\", \"advi\", \"advi\", \"agent\", \"agent\", \"agent\", \"agent\", \"agent\", \"alg\", \"alg\", \"alg\", \"alg\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"anagram\", \"anagram\", \"anagram\", \"anagram\", \"analog\", \"analog\", \"analog\", \"analog\", \"analog\", \"analog\", \"appearance\", \"appearance\", \"appearance\", \"appearance\", \"appearance\", \"apprenticeship\", \"apprenticeship\", \"apprenticeship\", \"apprenticeship\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approximate\", \"approximate\", \"approximate\", \"approximate\", \"approximate\", \"approximate\", \"approximation\", \"approximation\", \"approximation\", \"approximation\", \"approximation\", \"approximation\", \"arbor\", \"arbor\", \"arbor\", \"arbor\", \"architecture\", \"architecture\", \"architecture\", \"architecture\", \"architecture\", \"architecture\", \"architecture\", \"architecture\", \"arousal\", \"arousal\", \"arousal\", \"arousal\", \"arousal\", \"array\", \"array\", \"array\", \"array\", \"array\", \"array\", \"artificial_insect\", \"artificial_insect\", \"artificial_insect\", \"artificial_insect\", \"artificial_insect\", \"assignment\", \"assignment\", \"assignment\", \"assignment\", \"assignment\", \"associative_memory\", \"associative_memory\", \"associative_memory\", \"associative_memory\", \"attribute\", \"attribute\", \"attribute\", \"attribute\", \"auc\", \"auc\", \"auc\", \"auc\", \"audio\", \"audio\", \"audio\", \"audio\", \"audio\", \"audio\", \"average_cost\", \"average_cost\", \"average_cost\", \"average_cost\", \"average_cost\", \"bandit\", \"bandit\", \"bandit\", \"bandit\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"bds\", \"bds\", \"bds\", \"bds\", \"beer\", \"beer\", \"beer\", \"beer\", \"beer\", \"ber\", \"ber\", \"ber\", \"ber\", \"beta_coalescent\", \"beta_coalescent\", \"beta_coalescent\", \"beta_coalescent\", \"beta_coalescent\", \"bias\", \"bias\", \"bias\", \"bias\", \"bias\", \"bias\", \"bias_correction\", \"bias_correction\", \"bias_correction\", \"bias_correction\", \"bias_correction\", \"bigram\", \"bigram\", \"bigram\", \"bigram\", \"bite\", \"bite\", \"bite\", \"bite\", \"bite\", \"block\", \"block\", \"block\", \"block\", \"block\", \"bof\", \"bof\", \"bof\", \"bof\", \"bow\", \"bow\", \"bow\", \"bow\", \"bow\", \"bower\", \"bower\", \"bower\", \"bower\", \"bower\", \"box\", \"box\", \"box\", \"box\", \"box\", \"box\", \"bpg\", \"bpg\", \"bpg\", \"bpg\", \"break\", \"break\", \"break\", \"break\", \"break\", \"break\", \"burst\", \"burst\", \"burst\", \"burst\", \"burst\", \"burst\", \"cap_tcha\", \"cap_tcha\", \"cap_tcha\", \"cap_tcha\", \"cap_tcha\", \"captcha\", \"captcha\", \"captcha\", \"captcha\", \"captcha\", \"cascade\", \"cascade\", \"cascade\", \"cascade\", \"cascade\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"category\", \"category\", \"category\", \"category\", \"category\", \"causal\", \"causal\", \"causal\", \"causal\", \"cell\", \"cell\", \"cell\", \"cell\", \"cell\", \"cell\", \"center\", \"center\", \"center\", \"center\", \"center\", \"center\", \"cerebellar_cortex\", \"cerebellar_cortex\", \"cerebellar_cortex\", \"cerebellar_cortex\", \"cerebellar_cortex\", \"cerebellum\", \"cerebellum\", \"cerebellum\", \"cerebellum\", \"cerebellum\", \"cerebellum\", \"chain\", \"chain\", \"chain\", \"chain\", \"chain\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"cheffe\", \"cheffe\", \"cheffe\", \"cheffe\", \"cheffe\", \"chiel\", \"chiel\", \"chiel\", \"chiel\", \"chiel\", \"children_set\", \"children_set\", \"children_set\", \"children_set\", \"children_set\", \"chip\", \"chip\", \"chip\", \"chip\", \"chip\", \"circuit\", \"circuit\", \"circuit\", \"circuit\", \"circuit\", \"circuit\", \"circuit\", \"classification\", \"classification\", \"classification\", \"classification\", \"classification\", \"classification\", \"classifier\", \"classifier\", \"classifier\", \"classifier\", \"classifier\", \"classifier\", \"classifier\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"clustering\", \"clustering\", \"clustering\", \"clustering\", \"clustering\", \"clustering\", \"cmo\", \"cmo\", \"cmo\", \"cmo\", \"cnn\", \"cnn\", \"cnn\", \"cnn\", \"cnn\", \"coalescent\", \"coalescent\", \"coalescent\", \"coalescent\", \"coalescent\", \"color\", \"color\", \"color\", \"color\", \"color\", \"combinatorial\", \"combinatorial\", \"combinatorial\", \"combinatorial\", \"combinatorial\", \"combinatorial\", \"communication\", \"communication\", \"communication\", \"communication\", \"communication\", \"communication\", \"component\", \"component\", \"component\", \"component\", \"component\", \"component\", \"component\", \"comprise\", \"comprise\", \"comprise\", \"comprise\", \"comprise\", \"comprise\", \"comprise\", \"comprise\", \"computeplan\", \"computeplan\", \"computeplan\", \"computeplan\", \"computeplan\", \"concave\", \"concave\", \"concave\", \"concave\", \"concave\", \"concept\", \"concept\", \"concept\", \"concept\", \"concept\", \"concept\", \"concept\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"configuration\", \"configuration\", \"configuration\", \"configuration\", \"configuration\", \"configuration\", \"configure\", \"configure\", \"configure\", \"configure\", \"configure\", \"constraint\", \"constraint\", \"constraint\", \"constraint\", \"constraint\", \"constraint\", \"constraint\", \"constraint_generation\", \"constraint_generation\", \"constraint_generation\", \"constraint_generation\", \"consummatory\", \"consummatory\", \"consummatory\", \"consummatory\", \"consummatory\", \"contrast\", \"contrast\", \"contrast\", \"contrast\", \"contrast\", \"contrast\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control_law\", \"control_law\", \"control_law\", \"control_law\", \"control_law\", \"convention\", \"convention\", \"convention\", \"convention\", \"convention\", \"convex\", \"convex\", \"convex\", \"convex\", \"convex\", \"convex\", \"corollary\", \"corollary\", \"corollary\", \"corollary\", \"corollary\", \"corollary\", \"correlational\", \"correlational\", \"correlational\", \"correlational\", \"cortical\", \"cortical\", \"cortical\", \"cortical\", \"cortical\", \"cortical\", \"cortical_thickness\", \"cortical_thickness\", \"cortical_thickness\", \"cortical_thickness\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost_sensitive\", \"cost_sensitive\", \"cost_sensitive\", \"cost_sensitive\", \"covertype\", \"covertype\", \"covertype\", \"covertype\", \"covertype\", \"cpms\", \"cpms\", \"cpms\", \"cpms\", \"current\", \"current\", \"current\", \"current\", \"current\", \"current\", \"current\", \"current\", \"custom\", \"custom\", \"custom\", \"custom\", \"dac\", \"dac\", \"dac\", \"dac\", \"dag\", \"dag\", \"dag\", \"dag\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"demodulator\", \"demodulator\", \"demodulator\", \"demodulator\", \"denoise\", \"denoise\", \"denoise\", \"denoise\", \"denoiser\", \"denoiser\", \"denoiser\", \"denoiser\", \"denote\", \"denote\", \"denote\", \"denote\", \"denote\", \"denote\", \"density\", \"density\", \"density\", \"density\", \"density\", \"density\", \"design\", \"design\", \"design\", \"design\", \"design\", \"design\", \"design\", \"design\", \"designer\", \"designer\", \"designer\", \"designer\", \"detection\", \"detection\", \"detection\", \"detection\", \"detection\", \"detection\", \"detector\", \"detector\", \"detector\", \"detector\", \"detector\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"differential\", \"differential\", \"differential\", \"differential\", \"differential\", \"differential\", \"differential\", \"differential_cost\", \"differential_cost\", \"differential_cost\", \"differential_cost\", \"differential_cost\", \"digg\", \"digg\", \"digg\", \"digg\", \"digg\", \"digit\", \"digit\", \"digit\", \"digit\", \"digit\", \"digital\", \"digital\", \"digital\", \"digital\", \"digital\", \"digital\", \"dimensional\", \"dimensional\", \"dimensional\", \"dimensional\", \"dimensional\", \"dimensional\", \"diorio\", \"diorio\", \"diorio\", \"diorio\", \"disease\", \"disease\", \"disease\", \"disease\", \"distance\", \"distance\", \"distance\", \"distance\", \"distance\", \"distance\", \"distance_metric\", \"distance_metric\", \"distance_metric\", \"distance_metric\", \"distance_metric\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"divergence\", \"divergence\", \"divergence\", \"divergence\", \"divergence\", \"divergence\", \"document\", \"document\", \"document\", \"document\", \"document\", \"document\", \"dpmm\", \"dpmm\", \"dpmm\", \"dpmm\", \"dpmm\", \"dude\", \"dude\", \"dude\", \"dude\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamic\", \"edge\", \"edge\", \"edge\", \"edge\", \"edge\", \"edge\", \"effective_resistance\", \"effective_resistance\", \"effective_resistance\", \"effective_resistance\", \"enable\", \"enable\", \"enable\", \"enable\", \"enable\", \"enable\", \"engine\", \"engine\", \"engine\", \"engine\", \"engine\", \"ensemble\", \"ensemble\", \"ensemble\", \"ensemble\", \"ensemble\", \"ensemble\", \"equilibrium_point\", \"equilibrium_point\", \"equilibrium_point\", \"equilibrium_point\", \"ess\", \"ess\", \"ess\", \"ess\", \"ess\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimator\", \"estimator\", \"estimator\", \"estimator\", \"estimator\", \"estimator\", \"estimator\", \"exact_match\", \"exact_match\", \"exact_match\", \"exact_match\", \"exact_match\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"excitatory\", \"excitatory\", \"excitatory\", \"excitatory\", \"excitatory\", \"excitatory\", \"expected_return\", \"expected_return\", \"expected_return\", \"expected_return\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"eye\", \"eye\", \"eye\", \"eye\", \"eye\", \"eye\", \"face\", \"face\", \"face\", \"face\", \"face\", \"face\", \"face_detection\", \"face_detection\", \"face_detection\", \"face_detection\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feed\", \"feed\", \"feed\", \"feed\", \"feed\", \"feeding\", \"feeding\", \"feeding\", \"feeding\", \"feeding\", \"feeding_arousal\", \"feeding_arousal\", \"feeding_arousal\", \"feeding_arousal\", \"feeding_arousal\", \"fft\", \"fft\", \"fft\", \"fft\", \"field\", \"field\", \"field\", \"field\", \"field\", \"field\", \"field_programmable\", \"field_programmable\", \"field_programmable\", \"field_programmable\", \"field_programmable\", \"figueroa\", \"figueroa\", \"figueroa\", \"figueroa\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"fix\", \"fix\", \"fix\", \"fix\", \"fix\", \"fix\", \"fix\", \"floating_gate\", \"floating_gate\", \"floating_gate\", \"floating_gate\", \"floating_gate\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"food\", \"food\", \"food\", \"food\", \"food\", \"fpga\", \"fpga\", \"fpga\", \"fpga\", \"fpla\", \"fpla\", \"fpla\", \"fpla\", \"fpla\", \"frequency\", \"frequency\", \"frequency\", \"frequency\", \"frequency\", \"frequency\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"functionality\", \"functionality\", \"functionality\", \"functionality\", \"gaussian\", \"gaussian\", \"gaussian\", \"gaussian\", \"gaussian\", \"gaussian\", \"gaussian\", \"generate\", \"generate\", \"generate\", \"generate\", \"generate\", \"generate\", \"generate\", \"gij\", \"gij\", \"gij\", \"gij\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"gradient\", \"gradient\", \"gradient\", \"gradient\", \"gradient\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"grf\", \"grf\", \"grf\", \"grf\", \"grf\", \"grfs\", \"grfs\", \"grfs\", \"grfs\", \"grfs\", \"gsr\", \"gsr\", \"gsr\", \"gsr\", \"gsr\", \"gsr\", \"gss\", \"gss\", \"gss\", \"gss\", \"hardware\", \"hardware\", \"hardware\", \"hardware\", \"hardware\", \"hd\", \"hd\", \"hd\", \"hd\", \"head_movement\", \"head_movement\", \"head_movement\", \"head_movement\", \"head_movement\", \"head_velocity\", \"head_velocity\", \"head_velocity\", \"head_velocity\", \"head_velocity\", \"height\", \"height\", \"height\", \"height\", \"height\", \"hierarchical_cover\", \"hierarchical_cover\", \"hierarchical_cover\", \"hierarchical_cover\", \"hierarchical_cover\", \"hierarchy\", \"hierarchy\", \"hierarchy\", \"hierarchy\", \"hierarchy\", \"hmc\", \"hmc\", \"hmc\", \"hmc\", \"homogeneity\", \"homogeneity\", \"homogeneity\", \"homogeneity\", \"hsu\", \"hsu\", \"hsu\", \"hsu\", \"hyperedge\", \"hyperedge\", \"hyperedge\", \"hyperedge\", \"hypergraph\", \"hypergraph\", \"hypergraph\", \"hypergraph\", \"hz\", \"hz\", \"hz\", \"hz\", \"hz\", \"icf\", \"icf\", \"icf\", \"icf\", \"icf\", \"image\", \"image\", \"image\", \"image\", \"image\", \"image\", \"image\", \"implement\", \"implement\", \"implement\", \"implement\", \"implement\", \"implement\", \"implement\", \"implement\", \"implementation\", \"implementation\", \"implementation\", \"implementation\", \"implementation\", \"implementation\", \"implementation\", \"implementation\", \"incremental\", \"incremental\", \"incremental\", \"incremental\", \"incremental\", \"incremental\", \"indefinite_kernel\", \"indefinite_kernel\", \"indefinite_kernel\", \"indefinite_kernel\", \"individual\", \"individual\", \"individual\", \"individual\", \"individual\", \"individual\", \"individual\", \"individual_specific\", \"individual_specific\", \"individual_specific\", \"individual_specific\", \"inhibition\", \"inhibition\", \"inhibition\", \"inhibition\", \"inhibition\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"insect\", \"insect\", \"insect\", \"insect\", \"insect\", \"interaction\", \"interaction\", \"interaction\", \"interaction\", \"interaction\", \"interaction\", \"interconnect\", \"interconnect\", \"interconnect\", \"interconnect\", \"interconnect\", \"interconnect\", \"interest_rates\", \"interest_rates\", \"interest_rates\", \"interest_rates\", \"interface\", \"interface\", \"interface\", \"interface\", \"interface\", \"internal\", \"internal\", \"internal\", \"internal\", \"internal\", \"internal\", \"internal\", \"interplb\", \"interplb\", \"interplb\", \"interplb\", \"ipm\", \"ipm\", \"ipm\", \"ipm\", \"ipm\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kikuchi\", \"kikuchi\", \"kikuchi\", \"kikuchi\", \"kikuchi\", \"kikuchi_approximation\", \"kikuchi_approximation\", \"kikuchi_approximation\", \"kikuchi_approximation\", \"kikuchi_approximation\", \"kingmans_coalescent\", \"kingmans_coalescent\", \"kingmans_coalescent\", \"kingmans_coalescent\", \"kingmans_coalescent\", \"kupfermann\", \"kupfermann\", \"kupfermann\", \"kupfermann\", \"kupfermann\", \"kwik\", \"kwik\", \"kwik\", \"kwik\", \"label\", \"label\", \"label\", \"label\", \"label\", \"label\", \"label\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"lemma\", \"lemma\", \"lemma\", \"lemma\", \"lemma\", \"lemma\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"lndcg\", \"lndcg\", \"lndcg\", \"lndcg\", \"loan\", \"loan\", \"loan\", \"loan\", \"loan\", \"local\", \"local\", \"local\", \"local\", \"local\", \"local\", \"log\", \"log\", \"log\", \"log\", \"log\", \"log\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"lovasz_extension\", \"lovasz_extension\", \"lovasz_extension\", \"lovasz_extension\", \"lrr\", \"lrr\", \"lrr\", \"lrr\", \"lrr\", \"lrr\", \"lsda\", \"lsda\", \"lsda\", \"lsda\", \"lsda\", \"lstd\", \"lstd\", \"lstd\", \"lstd\", \"lstd\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"malach\", \"malach\", \"malach\", \"malach\", \"manifold\", \"manifold\", \"manifold\", \"manifold\", \"manifold\", \"manifold\", \"margin\", \"margin\", \"margin\", \"margin\", \"margin\", \"margin\", \"market\", \"market\", \"market\", \"market\", \"master\", \"master\", \"master\", \"master\", \"master\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"max_norm\", \"max_norm\", \"max_norm\", \"max_norm\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"mbp\", \"mbp\", \"mbp\", \"mbp\", \"mdp\", \"mdp\", \"mdp\", \"mdp\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"measurement\", \"measurement\", \"measurement\", \"measurement\", \"measurement\", \"measurement\", \"measurement\", \"memory\", \"memory\", \"memory\", \"memory\", \"memory\", \"memory\", \"message\", \"message\", \"message\", \"message\", \"message\", \"message\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"metric\", \"metric\", \"metric\", \"metric\", \"metric\", \"metric\", \"mfcc\", \"mfcc\", \"mfcc\", \"mfcc\", \"mfcc\", \"mfi\", \"mfi\", \"mfi\", \"mfi\", \"mfis\", \"mfis\", \"mfis\", \"mfis\", \"microfinance\", \"microfinance\", \"microfinance\", \"microfinance\", \"minimax_goal\", \"minimax_goal\", \"minimax_goal\", \"minimax_goal\", \"minimax_goal\", \"mixture\", \"mixture\", \"mixture\", \"mixture\", \"mixture\", \"mixture\", \"mkl\", \"mkl\", \"mkl\", \"mkl\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"motif\", \"motif\", \"motif\", \"motif\", \"motion_segmentation\", \"motion_segmentation\", \"motion_segmentation\", \"motion_segmentation\", \"motion_segmentation\", \"motion_segmentation\", \"motor\", \"motor\", \"motor\", \"motor\", \"motor\", \"motor\", \"movement\", \"movement\", \"movement\", \"movement\", \"movement\", \"movement\", \"msec\", \"msec\", \"msec\", \"msec\", \"msec\", \"multilabel\", \"multilabel\", \"multilabel\", \"multilabel\", \"multilabel\", \"near\", \"near\", \"near\", \"near\", \"near\", \"near\", \"neighbor\", \"neighbor\", \"neighbor\", \"neighbor\", \"neighbor\", \"neighbor\", \"neighbor\", \"neighborhood\", \"neighborhood\", \"neighborhood\", \"neighborhood\", \"neighborhood\", \"neighborhood\", \"neighborhood\", \"network\", \"network\", \"network\", \"network\", \"network\", \"network\", \"network\", \"neural_dude\", \"neural_dude\", \"neural_dude\", \"neural_dude\", \"neuron\", \"neuron\", \"neuron\", \"neuron\", \"neuron\", \"neuron\", \"nfet_plb\", \"nfet_plb\", \"nfet_plb\", \"nfet_plb\", \"nice_clustering\", \"nice_clustering\", \"nice_clustering\", \"nice_clustering\", \"nice_clustering\", \"node\", \"node\", \"node\", \"node\", \"node\", \"node\", \"noise\", \"noise\", \"noise\", \"noise\", \"noise\", \"noise\", \"non_deterministic\", \"non_deterministic\", \"non_deterministic\", \"non_deterministic\", \"nonstationary_covariance\", \"nonstationary_covariance\", \"nonstationary_covariance\", \"nonstationary_covariance\", \"nsn\", \"nsn\", \"nsn\", \"nsn\", \"nsn\", \"nsn\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"object\", \"object\", \"object\", \"object\", \"object\", \"object\", \"ocular_dominance\", \"ocular_dominance\", \"ocular_dominance\", \"ocular_dominance\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimality\", \"optimality\", \"optimality\", \"optimality\", \"optimality\", \"optimality\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"overhead\", \"overhead\", \"overhead\", \"overhead\", \"overhead\", \"overhead\", \"pah\", \"pah\", \"pah\", \"pah\", \"parallelize\", \"parallelize\", \"parallelize\", \"parallelize\", \"parallelize\", \"paraphrase\", \"paraphrase\", \"paraphrase\", \"paraphrase\", \"paraphrase\", \"parti_game\", \"parti_game\", \"parti_game\", \"parti_game\", \"parti_game\", \"parw\", \"parw\", \"parw\", \"parw\", \"pass\", \"pass\", \"pass\", \"pass\", \"pass\", \"pass\", \"pass\", \"payoff\", \"payoff\", \"payoff\", \"payoff\", \"perturbation\", \"perturbation\", \"perturbation\", \"perturbation\", \"perturbation\", \"phrase\", \"phrase\", \"phrase\", \"phrase\", \"phrase\", \"phrase\", \"picf\", \"picf\", \"picf\", \"picf\", \"picf\", \"pivot\", \"pivot\", \"pivot\", \"pivot\", \"pivot\", \"plan_execution\", \"plan_execution\", \"plan_execution\", \"plan_execution\", \"plan_execution\", \"play\", \"play\", \"play\", \"play\", \"play\", \"plb\", \"plb\", \"plb\", \"plb\", \"plb\", \"plp\", \"plp\", \"plp\", \"plp\", \"plp\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"policy\", \"policy\", \"policy\", \"policy\", \"policy\", \"policy\", \"positive_semidefinite\", \"positive_semidefinite\", \"positive_semidefinite\", \"positive_semidefinite\", \"positive_semidefinite\", \"positive_semidefinite\", \"postsynaptic\", \"postsynaptic\", \"postsynaptic\", \"postsynaptic\", \"postsynaptic\", \"pred\", \"pred\", \"pred\", \"pred\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"predictive\", \"predictive\", \"predictive\", \"predictive\", \"predictive\", \"predictive\", \"predictive\", \"predtron\", \"predtron\", \"predtron\", \"predtron\", \"preventive\", \"preventive\", \"preventive\", \"preventive\", \"primitive\", \"primitive\", \"primitive\", \"primitive\", \"primitive\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"process\", \"process\", \"process\", \"process\", \"process\", \"process\", \"process\", \"programming\", \"programming\", \"programming\", \"programming\", \"programming\", \"protein\", \"protein\", \"protein\", \"protein\", \"protein\", \"prototype\", \"prototype\", \"prototype\", \"prototype\", \"prototype\", \"pseudodimension\", \"pseudodimension\", \"pseudodimension\", \"pseudodimension\", \"psp\", \"psp\", \"psp\", \"psp\", \"psp\", \"psvm\", \"psvm\", \"psvm\", \"psvm\", \"psvm\", \"ptl\", \"ptl\", \"ptl\", \"ptl\", \"ptrain\", \"ptrain\", \"ptrain\", \"ptrain\", \"ptv\", \"ptv\", \"ptv\", \"ptv\", \"ptv\", \"quantile_regression\", \"quantile_regression\", \"quantile_regression\", \"quantile_regression\", \"query\", \"query\", \"query\", \"query\", \"query\", \"query\", \"rae\", \"rae\", \"rae\", \"rae\", \"random\", \"random\", \"random\", \"random\", \"random\", \"random\", \"random\", \"randsvm\", \"randsvm\", \"randsvm\", \"randsvm\", \"rank\", \"rank\", \"rank\", \"rank\", \"rank\", \"rank\", \"rapid_prototype\", \"rapid_prototype\", \"rapid_prototype\", \"rapid_prototype\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"recaptcha\", \"recaptcha\", \"recaptcha\", \"recaptcha\", \"recaptcha\", \"reconfigurable\", \"reconfigurable\", \"reconfigurable\", \"reconfigurable\", \"reconfigurable\", \"reconstruction\", \"reconstruction\", \"reconstruction\", \"reconstruction\", \"reconstruction\", \"recursive_autoencoder\", \"recursive_autoencoder\", \"recursive_autoencoder\", \"recursive_autoencoder\", \"ree\", \"ree\", \"ree\", \"ree\", \"ree\", \"reflex\", \"reflex\", \"reflex\", \"reflex\", \"reflex\", \"region\", \"region\", \"region\", \"region\", \"region\", \"region\", \"reinforced_neuron\", \"reinforced_neuron\", \"reinforced_neuron\", \"reinforced_neuron\", \"reinforced_neuron\", \"relaxation\", \"relaxation\", \"relaxation\", \"relaxation\", \"relaxation\", \"rep\", \"rep\", \"rep\", \"rep\", \"rep\", \"representation\", \"representation\", \"representation\", \"representation\", \"representation\", \"representation\", \"residual_gradient\", \"residual_gradient\", \"residual_gradient\", \"residual_gradient\", \"residual_gradient\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"rf\", \"rf\", \"rf\", \"rf\", \"rf\", \"rf\", \"rhs\", \"rhs\", \"rhs\", \"rhs\", \"rhs\", \"rhs\", \"rooted_tree\", \"rooted_tree\", \"rooted_tree\", \"rooted_tree\", \"rooted_tree\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"satiation\", \"satiation\", \"satiation\", \"satiation\", \"satiation\", \"scan_statistic\", \"scan_statistic\", \"scan_statistic\", \"scan_statistic\", \"scheffe\", \"scheffe\", \"scheffe\", \"scheffe\", \"scheffe\", \"score\", \"score\", \"score\", \"score\", \"score\", \"search\", \"search\", \"search\", \"search\", \"search\", \"search\", \"segment\", \"segment\", \"segment\", \"segment\", \"segment\", \"segment\", \"semantic_correlation\", \"semantic_correlation\", \"semantic_correlation\", \"semantic_correlation\", \"sensory\", \"sensory\", \"sensory\", \"sensory\", \"sensory\", \"sensory\", \"sentence\", \"sentence\", \"sentence\", \"sentence\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"shape\", \"shape\", \"shape\", \"shape\", \"shape\", \"shon\", \"shon\", \"shon\", \"shon\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"silicon\", \"silicon\", \"silicon\", \"silicon\", \"silicon\", \"slg\", \"slg\", \"slg\", \"slg\", \"snow\", \"snow\", \"snow\", \"snow\", \"snps\", \"snps\", \"snps\", \"snps\", \"solution\", \"solution\", \"solution\", \"solution\", \"solution\", \"solution\", \"solution\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"span\", \"span\", \"span\", \"span\", \"span\", \"span\", \"spatial_frequency\", \"spatial_frequency\", \"spatial_frequency\", \"spatial_frequency\", \"spectral_clustere\", \"spectral_clustere\", \"spectral_clustere\", \"spectral_clustere\", \"spectral_clustere\", \"speedup\", \"speedup\", \"speedup\", \"speedup\", \"speedup\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike_time\", \"spike_time\", \"spike_time\", \"spike_time\", \"spike_time\", \"spike_train\", \"spike_train\", \"spike_train\", \"spike_train\", \"spike_train\", \"spike_trajectorie\", \"spike_trajectorie\", \"spike_trajectorie\", \"spike_trajectorie\", \"spike_trajectorie\", \"spikes_volley\", \"spikes_volley\", \"spikes_volley\", \"spikes_volley\", \"spikes_volley\", \"splitting\", \"splitting\", \"splitting\", \"splitting\", \"splitting\", \"splitting\", \"ssc\", \"ssc\", \"ssc\", \"ssc\", \"ssc\", \"ssc\", \"stan\", \"stan\", \"stan\", \"stan\", \"star_path\", \"star_path\", \"star_path\", \"star_path\", \"star_path\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"stdp\", \"stdp\", \"stdp\", \"stdp\", \"stdp\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step_ahead\", \"step_ahead\", \"step_ahead\", \"step_ahead\", \"stochastic\", \"stochastic\", \"stochastic\", \"stochastic\", \"stochastic\", \"stochastic\", \"stochastic\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"submodular\", \"submodular\", \"submodular\", \"submodular\", \"submodular\", \"submodular_minimization\", \"submodular_minimization\", \"submodular_minimization\", \"submodular_minimization\", \"subspace\", \"subspace\", \"subspace\", \"subspace\", \"subspace\", \"subspace\", \"subtree\", \"subtree\", \"subtree\", \"subtree\", \"subtree\", \"subtree\", \"subtype\", \"subtype\", \"subtype\", \"subtype\", \"suppression\", \"suppression\", \"suppression\", \"suppression\", \"suppression\", \"svm\", \"svm\", \"svm\", \"svm\", \"svm\", \"svm\", \"svm\", \"symbolic\", \"symbolic\", \"symbolic\", \"symbolic\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"target\", \"target\", \"target\", \"target\", \"target\", \"target\", \"task\", \"task\", \"task\", \"task\", \"task\", \"task\", \"task\", \"tcha\", \"tcha\", \"tcha\", \"tcha\", \"tcha\", \"tchas\", \"tchas\", \"tchas\", \"tchas\", \"tchas\", \"teacher\", \"teacher\", \"teacher\", \"teacher\", \"teacher\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"thin_junction\", \"thin_junction\", \"thin_junction\", \"thin_junction\", \"third_order\", \"third_order\", \"third_order\", \"third_order\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"tissue\", \"tissue\", \"tissue\", \"tissue\", \"tissue\", \"trace\", \"trace\", \"trace\", \"trace\", \"trace\", \"trace\", \"tracker\", \"tracker\", \"tracker\", \"tracker\", \"training\", \"training\", \"training\", \"training\", \"training\", \"training\", \"training\", \"trait\", \"trait\", \"trait\", \"trait\", \"trajectory\", \"trajectory\", \"trajectory\", \"trajectory\", \"trajectory\", \"trajectory\", \"trajectory\", \"transistor\", \"transistor\", \"transistor\", \"transistor\", \"transistor\", \"tree\", \"tree\", \"tree\", \"tree\", \"tree\", \"tree\", \"treewidth\", \"treewidth\", \"treewidth\", \"treewidth\", \"treewidth_bound\", \"treewidth_bound\", \"treewidth_bound\", \"treewidth_bound\", \"triangulation\", \"triangulation\", \"triangulation\", \"triangulation\", \"tsc\", \"tsc\", \"tsc\", \"tsc\", \"tsc\", \"tsc\", \"tsvm\", \"tsvm\", \"tsvm\", \"tsvm\", \"unfold\", \"unfold\", \"unfold\", \"unfold\", \"unit\", \"unit\", \"unit\", \"unit\", \"unit\", \"unit\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"user\", \"user\", \"user\", \"user\", \"user\", \"user\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"variance\", \"variance\", \"variance\", \"variance\", \"variance\", \"variance\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"velocity\", \"velocity\", \"velocity\", \"velocity\", \"velocity\", \"vertex\", \"vertex\", \"vertex\", \"vertex\", \"vertex\", \"vertex\", \"video\", \"video\", \"video\", \"video\", \"video\", \"video\", \"view\", \"view\", \"view\", \"view\", \"view\", \"view\", \"view\", \"village\", \"village\", \"village\", \"village\", \"viola_jone\", \"viola_jone\", \"viola_jone\", \"viola_jone\", \"vlsi\", \"vlsi\", \"vlsi\", \"vlsi\", \"vlsi\", \"vor\", \"vor\", \"vor\", \"vor\", \"vor\", \"wavelet\", \"wavelet\", \"wavelet\", \"wavelet\", \"webpage\", \"webpage\", \"webpage\", \"webpage\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"xi\", \"xi\", \"xi\", \"xi\", \"xi\", \"xi\", \"xji\", \"xji\", \"xji\", \"xji\", \"xtk\", \"xtk\", \"xtk\", \"xtk\"]}, \"mdsDat\": {\"y\": [0.03151330983314255, -0.03396919399903692, 0.01566832835189079, -0.023795914637586967, 0.040608839566007505, -0.04766868712245604, 0.025378557817740895, -0.007735239809701804], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [32.59852981567383, 20.686473846435547, 19.285720825195312, 12.964822769165039, 7.0734477043151855, 4.464208126068115, 2.4401848316192627, 0.48661595582962036], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8], \"x\": [-0.0993151681157516, -0.07682645802953342, -0.06142761661691254, -0.0393067540181895, 0.017008515090811874, 0.03307983557264393, 0.09626131821180944, 0.13052632790512161]}, \"R\": 30, \"lambda.step\": 0.01, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\"], \"Term\": [\"neuron\", \"algorithm\", \"policy\", \"cluster\", \"sample\", \"circuit\", \"spike\", \"state\", \"control\", \"optimal\", \"subspace\", \"node\", \"point\", \"system\", \"machine\", \"clustering\", \"problem\", \"mixture\", \"log\", \"dynamic\", \"noise\", \"view\", \"estimator\", \"matrix\", \"cell\", \"learn\", \"vertex\", \"detection\", \"feature\", \"gradient\", \"motif\", \"teacher\", \"treewidth\", \"parw\", \"convention\", \"eye\", \"anagram\", \"protein\", \"pah\", \"treewidth_bound\", \"cpms\", \"associative_memory\", \"bigram\", \"payoff\", \"ocular_dominance\", \"triangulation\", \"rf\", \"apprenticeship\", \"arbor\", \"symbolic\", \"thin_junction\", \"hd\", \"gij\", \"absorb\", \"circuit\", \"mbp\", \"interaction\", \"kwik\", \"malach\", \"play\", \"neuron\", \"memory\", \"agent\", \"tree\", \"chain\", \"communication\", \"engine\", \"shape\", \"trace\", \"assignment\", \"model\", \"cortical\", \"block\", \"edge\", \"local\", \"input\", \"target\", \"hierarchy\", \"unit\", \"time\", \"probability\", \"learn\", \"network\", \"rate\", \"datum\", \"set\", \"figure\", \"number\", \"show\", \"function\", \"algorithm\", \"result\", \"state\", \"may\", \"use\", \"structure\", \"weight\", \"case\", \"step\", \"value\", \"give\", \"large\", \"also\", \"method\", \"different\", \"problem\", \"advi\", \"demodulator\", \"non_deterministic\", \"tsvm\", \"policy\", \"submodular\", \"hypergraph\", \"bandit\", \"step_ahead\", \"bpg\", \"constraint_generation\", \"indefinite_kernel\", \"expected_return\", \"relaxation\", \"slg\", \"pseudodimension\", \"scan_statistic\", \"randsvm\", \"alg\", \"effective_resistance\", \"fft\", \"hyperedge\", \"lovasz_extension\", \"submodular_minimization\", \"gss\", \"positive_semidefinite\", \"mdp\", \"combinatorial\", \"nonstationary_covariance\", \"stan\", \"gradient\", \"programming\", \"concave\", \"predictive\", \"corollary\", \"convex\", \"optimal\", \"problem\", \"function\", \"matrix\", \"solution\", \"approximation\", \"state\", \"optimization\", \"graph\", \"method\", \"kernel\", \"algorithm\", \"svm\", \"action\", \"use\", \"stochastic\", \"random\", \"approximate\", \"set\", \"linear\", \"log\", \"model\", \"estimate\", \"sample\", \"space\", \"follow\", \"value\", \"approach\", \"datum\", \"result\", \"point\", \"number\", \"give\", \"show\", \"time\", \"learn\", \"dude\", \"neural_dude\", \"sentence\", \"paraphrase\", \"snow\", \"denoise\", \"cascade\", \"face_detection\", \"subtype\", \"bds\", \"viola_jone\", \"bow\", \"mkl\", \"tracker\", \"rae\", \"trait\", \"ber\", \"xtk\", \"cortical_thickness\", \"bof\", \"attribute\", \"individual_specific\", \"third_order\", \"denoiser\", \"disease\", \"reconstruction\", \"wavelet\", \"ess\", \"unfold\", \"recursive_autoencoder\", \"snps\", \"appearance\", \"ensemble\", \"hmc\", \"phrase\", \"face\", \"concept\", \"measurement\", \"feature\", \"box\", \"individual\", \"image\", \"trajectory\", \"classifier\", \"color\", \"use\", \"representation\", \"video\", \"model\", \"learn\", \"base\", \"method\", \"show\", \"vector\", \"kernel\", \"time\", \"example\", \"set\", \"distribution\", \"give\", \"algorithm\", \"sequence\", \"process\", \"approach\", \"object\", \"result\", \"datum\", \"number\", \"weight\", \"figure\", \"function\", \"problem\", \"value\", \"sample\", \"network\", \"training\", \"auc\", \"village\", \"dag\", \"mfis\", \"mfi\", \"max_norm\", \"microfinance\", \"multilabel\", \"loan\", \"equilibrium_point\", \"semantic_correlation\", \"market\", \"ptl\", \"pred\", \"lndcg\", \"xji\", \"webpage\", \"cost_sensitive\", \"rep\", \"burst\", \"quantile_regression\", \"ptrain\", \"ree\", \"predtron\", \"interest_rates\", \"suppression\", \"causal\", \"preventive\", \"homogeneity\", \"spatial_frequency\", \"spectral_clustere\", \"inhibition\", \"view\", \"document\", \"distance_metric\", \"manifold\", \"metric\", \"rank\", \"field\", \"margin\", \"loss\", \"prediction\", \"problem\", \"learn\", \"label\", \"datum\", \"constraint\", \"score\", \"function\", \"contrast\", \"distance\", \"test\", \"set\", \"algorithm\", \"give\", \"xi\", \"use\", \"task\", \"vector\", \"follow\", \"result\", \"example\", \"denote\", \"show\", \"matrix\", \"approach\", \"model\", \"case\", \"base\", \"also\", \"different\", \"first\", \"node\", \"parti_game\", \"insect\", \"nice_clustering\", \"coalescent\", \"dpmm\", \"lsda\", \"beta_coalescent\", \"cnn\", \"bite\", \"computeplan\", \"food\", \"grf\", \"kingmans_coalescent\", \"satiation\", \"minimax_goal\", \"grfs\", \"tissue\", \"chiel\", \"feeding\", \"feeding_arousal\", \"children_set\", \"consummatory\", \"artificial_insect\", \"arousal\", \"plan_execution\", \"rhs\", \"incremental\", \"kikuchi_approximation\", \"beer\", \"kupfermann\", \"kikuchi\", \"category\", \"average_cost\", \"optimality\", \"cluster\", \"query\", \"clustering\", \"differential_cost\", \"cell\", \"user\", \"adaptation\", \"message\", \"detection\", \"center\", \"detector\", \"node\", \"feed\", \"search\", \"classification\", \"state\", \"algorithm\", \"cost\", \"set\", \"network\", \"label\", \"point\", \"show\", \"datum\", \"object\", \"use\", \"figure\", \"distribution\", \"region\", \"also\", \"example\", \"result\", \"method\", \"model\", \"image\", \"hierarchical_cover\", \"psvm\", \"speedup\", \"nsn\", \"icf\", \"lstd\", \"height\", \"subspace\", \"ssc\", \"picf\", \"ipm\", \"pivot\", \"residual_gradient\", \"lrr\", \"tsc\", \"star_path\", \"overhead\", \"master\", \"estimator\", \"bias_correction\", \"rooted_tree\", \"cheffe\", \"covertype\", \"motion_segmentation\", \"gsr\", \"ptv\", \"divergence\", \"span\", \"scheffe\", \"parallelize\", \"subtree\", \"neighbor\", \"mixture\", \"splitting\", \"neighborhood\", \"near\", \"bias\", \"sample\", \"machine\", \"cluster\", \"point\", \"algorithm\", \"vertex\", \"clustering\", \"log\", \"mean\", \"variance\", \"component\", \"density\", \"distribution\", \"lemma\", \"time\", \"fix\", \"estimate\", \"give\", \"step\", \"dimensional\", \"matrix\", \"use\", \"show\", \"gaussian\", \"learn\", \"datum\", \"set\", \"vor\", \"tchas\", \"tcha\", \"captcha\", \"cap_tcha\", \"psp\", \"head_movement\", \"control_law\", \"stdp\", \"cerebellum\", \"msec\", \"cerebellar_cortex\", \"spikes_volley\", \"spike_trajectorie\", \"exact_match\", \"digg\", \"hz\", \"velocity\", \"movement\", \"motor\", \"spike_time\", \"segment\", \"plp\", \"recaptcha\", \"reflex\", \"audio\", \"mfcc\", \"spike\", \"bower\", \"head_velocity\", \"reinforced_neuron\", \"perturbation\", \"digit\", \"postsynaptic\", \"control\", \"sensory\", \"neuron\", \"pass\", \"dynamic\", \"break\", \"system\", \"noise\", \"cost\", \"optimal\", \"frequency\", \"excitatory\", \"internal\", \"task\", \"change\", \"use\", \"spike_train\", \"condition\", \"input\", \"generate\", \"experiment\", \"time\", \"fpla\", \"plb\", \"chip\", \"vlsi\", \"reconfigurable\", \"interconnect\", \"floating_gate\", \"silicon\", \"transistor\", \"array\", \"primitive\", \"hardware\", \"field_programmable\", \"digital\", \"diorio\", \"rapid_prototype\", \"interplb\", \"interface\", \"correlational\", \"shon\", \"figueroa\", \"hsu\", \"analog\", \"cmo\", \"configure\", \"functionality\", \"designer\", \"fpga\", \"nfet_plb\", \"dac\", \"comprise\", \"circuit\", \"prototype\", \"custom\", \"enable\", \"design\", \"implement\", \"learning\", \"current\", \"configuration\", \"differential\", \"architecture\", \"system\", \"machine\", \"adaptation\", \"learn\", \"input\", \"implementation\"], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.0698000192642212, 1.0676000118255615, 1.0543999671936035, 1.044700026512146, 1.0348000526428223, 1.0318000316619873, 1.0318000316619873, 1.0293999910354614, 1.0210000276565552, 1.0191999673843384, 1.006700038909912, 1.0027999877929688, 0.9958999752998352, 0.9958000183105469, 0.9926000237464905, 0.9868999719619751, 0.9857000112533569, 0.9818000197410583, 0.9786999821662903, 0.9775000214576721, 0.9767000079154968, 0.9764000177383423, 0.9764000177383423, 0.974399983882904, 0.9728000164031982, 0.97079998254776, 0.9681000113487244, 0.964900016784668, 0.9631999731063843, 0.9607999920845032, 0.9513999819755554, 0.9513999819755554, 0.871999979019165, 0.8492000102996826, 0.9280999898910522, 0.916100025177002, 0.9222000241279602, 0.8277999758720398, 0.8705999851226807, 0.890500009059906, 0.4916999936103821, 0.8277999758720398, 0.8202999830245972, 0.7533000111579895, 0.7620999813079834, 0.6075000166893005, 0.7141000032424927, 0.8510000109672546, 0.7371000051498413, 0.39340001344680786, 0.5008000135421753, 0.2847999930381775, 0.427700012922287, 0.4903999865055084, 0.2433999925851822, 0.1907999962568283, 0.365200012922287, 0.32339999079704285, 0.21739999949932098, 0.08810000121593475, 0.049300000071525574, 0.21369999647140503, 0.23960000276565552, 0.4262999892234802, -0.061799999326467514, 0.43700000643730164, 0.3928000032901764, 0.2948000133037567, 0.45969998836517334, 0.22059999406337738, 0.08699999749660492, 0.3278000056743622, 0.2013999968767166, -0.04910000041127205, 0.27649998664855957, -0.40610000491142273, 1.4890999794006348, 1.4768999814987183, 1.4738999605178833, 1.4692000150680542, 1.4686000347137451, 1.4681999683380127, 1.4608999490737915, 1.4465999603271484, 1.44350004196167, 1.4428999423980713, 1.4384000301361084, 1.430999994277954, 1.4283000230789185, 1.4072999954223633, 1.3977999687194824, 1.3976999521255493, 1.3878999948501587, 1.3863999843597412, 1.3830000162124634, 1.3743000030517578, 1.371399998664856, 1.3687000274658203, 1.3645000457763672, 1.3628000020980835, 1.3609999418258667, 1.3590999841690063, 1.3564000129699707, 1.354200005531311, 1.3476999998092651, 1.3385000228881836, 1.3164000511169434, 1.2706999778747559, 1.3027000427246094, 1.2051000595092773, 1.1859999895095825, 1.024999976158142, 0.8407999873161316, 0.7074999809265137, 0.597000002861023, 0.7484999895095825, 0.7968999743461609, 0.8561000227928162, 0.6057999730110168, 0.8108999729156494, 0.7422000169754028, 0.43700000643730164, 0.645799994468689, 0.22769999504089355, 0.9420999884605408, 0.7214000225067139, 0.17149999737739563, 0.942300021648407, 0.698199987411499, 0.7714999914169312, 0.08150000125169754, 0.47749999165534973, 0.423799991607666, -0.16949999332427979, 0.4957999885082245, 0.28450000286102295, 0.46160000562667847, 0.26989999413490295, 0.2506999969482422, 0.31679999828338623, -0.07609999924898148, 0.03519999980926514, 0.28600001335144043, 0.0778999999165535, 0.01080000028014183, -0.17470000684261322, -0.19419999420642853, -0.4887000024318695, 1.5634000301361084, 1.5615999698638916, 1.5480999946594238, 1.5435999631881714, 1.5362000465393066, 1.535599946975708, 1.527400016784668, 1.5266000032424927, 1.5264999866485596, 1.520400047302246, 1.5025999546051025, 1.5018999576568604, 1.5017999410629272, 1.5017000436782837, 1.5013999938964844, 1.500599980354309, 1.4931000471115112, 1.4847999811172485, 1.4800000190734863, 1.478600025177002, 1.4664000272750854, 1.4586000442504883, 1.457900047302246, 1.448699951171875, 1.4479000568389893, 1.444700002670288, 1.440999984741211, 1.4381999969482422, 1.4354000091552734, 1.4352999925613403, 1.4226000308990479, 1.4121999740600586, 1.409500002861023, 1.3853000402450562, 1.4046000242233276, 1.2044999599456787, 1.2682000398635864, 1.3135000467300415, 0.9696999788284302, 1.294600009918213, 1.1572999954223633, 0.8431000113487244, 1.263700008392334, 1.1031999588012695, 1.1888999938964844, 0.33640000224113464, 0.8845999836921692, 1.2724000215530396, 0.0017000000225380063, 0.11640000343322754, 0.41359999775886536, 0.20589999854564667, 0.11670000106096268, 0.4668999910354614, 0.5005000233650208, 0.11969999969005585, 0.2773999869823456, -0.13030000030994415, 0.25380000472068787, 0.07900000363588333, -0.25769999623298645, 0.6510000228881836, 0.4408999979496002, 0.23839999735355377, 0.6887000203132629, -0.08640000224113464, -0.2597000002861023, -0.023600000888109207, 0.295199990272522, 0.00039999998989515007, -0.4959000051021576, -0.33500000834465027, 0.013899999670684338, -0.04089999943971634, -0.009999999776482582, 0.21299999952316284, 1.9567999839782715, 1.9388999938964844, 1.9184999465942383, 1.9141000509262085, 1.90339994430542, 1.8919999599456787, 1.891800045967102, 1.8859000205993652, 1.881500005722046, 1.8783999681472778, 1.8737000226974487, 1.8481999635696411, 1.8257999420166016, 1.822100043296814, 1.8121999502182007, 1.8105000257492065, 1.7927000522613525, 1.7924000024795532, 1.7826000452041626, 1.7819000482559204, 1.7813999652862549, 1.7803000211715698, 1.778499960899353, 1.7767000198364258, 1.7648999691009521, 1.7591999769210815, 1.757699966430664, 1.7559000253677368, 1.7520999908447266, 1.748900055885315, 1.7157000303268433, 1.6936999559402466, 1.4815000295639038, 1.5393999814987183, 1.7089999914169312, 1.5449999570846558, 1.4977999925613403, 1.2977999448776245, 1.3118000030517578, 1.1722999811172485, 0.9606000185012817, 0.8392000198364258, 0.42559999227523804, 0.32170000672340393, 0.7401000261306763, 0.27149999141693115, 0.7911999821662903, 1.0528000593185425, -0.01119999960064888, 1.1217999458312988, 0.9387999773025513, 0.5353000164031982, -0.06509999930858612, -0.12630000710487366, 0.1615999937057495, 0.9142000079154968, -0.19609999656677246, 0.48350000381469727, 0.4399999976158142, 0.25369998812675476, 0.03009999915957451, 0.22200000286102295, 0.5667999982833862, -0.1014999970793724, 0.17949999868869781, 0.25940001010894775, -0.5647000074386597, 0.21850000321865082, 0.12290000170469284, 0.09210000187158585, 0.22470000386238098, 0.1656000018119812, 0.1388999968767166, 2.4690001010894775, 2.461400032043457, 2.4305999279022217, 2.4017999172210693, 2.382200002670288, 2.363300085067749, 2.341900110244751, 2.3285000324249268, 2.3164000511169434, 2.313499927520752, 2.27020001411438, 2.2681000232696533, 2.2639000415802, 2.26200008392334, 2.260499954223633, 2.2427000999450684, 2.2400999069213867, 2.240000009536743, 2.2397000789642334, 2.2392001152038574, 2.2221999168395996, 2.2149999141693115, 2.2144999504089355, 2.21370005607605, 2.2109999656677246, 2.210599899291992, 2.205899953842163, 2.2047998905181885, 2.186199903488159, 2.1858999729156494, 2.181999921798706, 2.067699909210205, 2.049099922180176, 1.7871999740600586, 1.5302000045776367, 1.7900999784469604, 1.6045000553131104, 1.982800006866455, 1.6308000087738037, 1.761199951171875, 1.9807000160217285, 1.7490999698638916, 1.4723999500274658, 1.6640000343322754, 1.7818000316619873, 0.9623000025749207, 2.0058000087738037, 1.1446000337600708, 0.9470999836921692, 0.3767000138759613, 0.02019999921321869, 1.3294999599456787, 0.03790000081062317, 0.3237000107765198, 0.5302000045776367, 0.23690000176429749, -0.20630000531673431, -0.3149000108242035, 0.7260000109672546, -0.5425999760627747, -0.05999999865889549, 0.008899999782443047, 0.7297999858856201, -0.1517000049352646, -0.2312999963760376, -0.5683000087738037, -0.5870000123977661, -1.3473999500274658, -0.12370000034570694, 2.913100004196167, 2.8921000957489014, 2.8341000080108643, 2.824399948120117, 2.7221999168395996, 2.6760001182556152, 2.672600030899048, 2.634999990463257, 2.6310999393463135, 2.623699903488159, 2.622299909591675, 2.6215999126434326, 2.6103999614715576, 2.60509991645813, 2.5452001094818115, 2.504199981689453, 2.4972000122070312, 2.4767000675201416, 2.4679999351501465, 2.447499990463257, 2.421600103378296, 2.398400068283081, 2.3954999446868896, 2.3852999210357666, 2.3815999031066895, 2.36899995803833, 2.3587000370025635, 2.340100049972534, 2.3357999324798584, 2.335200071334839, 2.30430006980896, 2.2158000469207764, 1.940600037574768, 2.303999900817871, 2.023400068283081, 2.2042999267578125, 1.730299949645996, 0.8622999787330627, 1.0463999509811401, 1.0198999643325806, 0.7512000203132629, 0.3167000114917755, 1.1658999919891357, 1.1658999919891357, 0.7501999735832214, 0.7379000186920166, 1.217900037765503, 0.850600004196167, 1.1962000131607056, 0.2502000033855438, 1.0144000053405762, -0.03350000083446503, 0.9061999917030334, 0.37869998812675476, -0.1535000056028366, 0.38589999079704285, 1.0648000240325928, -0.07259999960660934, -0.7835000157356262, -0.49559998512268066, 0.3425000011920929, -0.8460000157356262, -0.8266000151634216, -1.1079000234603882, 3.4493000507354736, 3.2446000576019287, 3.243799924850464, 3.17330002784729, 3.0761001110076904, 3.0234999656677246, 3.0078999996185303, 2.998500108718872, 2.989500045776367, 2.973900079727173, 2.971299886703491, 2.9700000286102295, 2.936500072479248, 2.8889000415802, 2.884000062942505, 2.8835999965667725, 2.8749001026153564, 2.871799945831299, 2.8659000396728516, 2.850600004196167, 2.836400032043457, 2.8296000957489014, 2.828000068664551, 2.8278000354766846, 2.8250999450683594, 2.7929000854492188, 2.764699935913086, 2.697700023651123, 2.6898999214172363, 2.688999891281128, 2.676500082015991, 2.6215999126434326, 2.4653000831604004, 2.63919997215271, 1.8616000413894653, 2.370300054550171, 1.2569999694824219, 1.903499960899353, 1.3423999547958374, 2.4089999198913574, 0.6782000064849854, 0.9761999845504761, 1.3980000019073486, 0.43220001459121704, 1.5986000299453735, 2.0566000938415527, 1.710800051689148, 0.1598999947309494, 0.5189999938011169, -0.9244999885559082, 2.002000093460083, 0.3553999960422516, -0.3287000060081482, 0.26080000400543213, -0.027899999171495438, -1.1153000593185425, 4.530600070953369, 4.428599834442139, 4.09089994430542, 3.648200035095215, 3.647900104522705, 3.5876998901367188, 3.5088999271392822, 3.4305999279022217, 3.428800106048584, 3.349400043487549, 3.255500078201294, 3.2441999912261963, 3.2348999977111816, 3.1774001121520996, 3.11680006980896, 2.9760000705718994, 2.9758999347686768, 2.9565999507904053, 2.833400011062622, 2.806999921798706, 2.8066999912261963, 2.805999994277954, 2.753200054168701, 2.6428000926971436, 2.6287999153137207, 2.594899892807007, 2.5947999954223633, 2.5947999954223633, 2.5943000316619873, 2.5941998958587646, 2.5706000328063965, 2.401700019836426, 2.3125, 2.4834001064300537, 2.064300060272217, 1.2171000242233276, 1.100100040435791, -0.06809999793767929, 0.6704999804496765, 1.330199956893921, 1.896299958229065, 0.7462000250816345, -0.5040000081062317, -0.40950000286102295, 1.4889999628067017, -1.5390000343322754, -0.9049000144004822, 0.5092999935150146], \"Freq\": [233.0, 1165.0, 273.0, 257.0, 519.0, 70.0, 87.0, 638.0, 132.0, 400.0, 93.0, 410.0, 441.0, 325.0, 274.0, 168.0, 834.0, 124.0, 386.0, 142.0, 184.0, 189.0, 75.0, 501.0, 127.0, 1023.0, 168.0, 145.0, 406.0, 215.0, 67.20113372802734, 62.140010833740234, 52.29312515258789, 43.80598449707031, 62.835289001464844, 51.25410842895508, 34.570709228515625, 71.88461303710938, 31.043149948120117, 30.190658569335938, 26.730182647705078, 25.84892463684082, 24.142122268676758, 29.339523315429688, 24.020166397094727, 22.390527725219727, 79.7665786743164, 21.527894973754883, 25.780195236206055, 25.03319549560547, 20.667055130004883, 20.6475830078125, 20.657392501831055, 25.799482345581055, 60.58822250366211, 19.798349380493164, 96.855712890625, 18.93865966796875, 18.886377334594727, 56.35566711425781, 197.40623474121094, 130.30995178222656, 198.669189453125, 305.2779846191406, 53.43142318725586, 61.25715255737305, 38.71674728393555, 90.3335189819336, 58.556785583496094, 48.695167541503906, 794.1334838867188, 76.80989074707031, 74.36193084716797, 109.71465301513672, 101.05575561523438, 222.0756378173828, 125.9310073852539, 59.68101119995117, 101.16123962402344, 353.65087890625, 220.16539001464844, 443.49566650390625, 247.3660888671875, 200.07977294921875, 378.12371826171875, 432.8044128417969, 265.069580078125, 269.7195129394531, 331.93646240234375, 417.8590393066406, 399.2524719238281, 278.94610595703125, 264.5743713378906, 182.75, 359.8273620605469, 165.22476196289062, 173.87765502929688, 198.5389404296875, 157.47193908691406, 201.54054260253906, 233.21665954589844, 173.2130889892578, 190.9534912109375, 211.71038818359375, 173.3426513671875, 181.23690795898438, 37.27210998535156, 32.45720291137695, 30.927873611450195, 29.351747512817383, 245.87130737304688, 40.483001708984375, 40.28470230102539, 25.178905487060547, 23.70537567138672, 22.992799758911133, 23.569868087768555, 21.33587074279785, 20.59402084350586, 36.971649169921875, 17.296974182128906, 17.95791244506836, 16.460491180419922, 15.782914161682129, 15.726672172546387, 14.934252738952637, 21.323774337768555, 16.72752571105957, 14.147074699401855, 14.124086380004883, 14.090275764465332, 20.120697021484375, 42.631370544433594, 27.89396095275879, 12.643939971923828, 15.013505935668945, 166.11216735839844, 42.56877136230469, 23.892892837524414, 37.31350326538086, 39.43411636352539, 85.78733825683594, 191.95126342773438, 350.2404479980469, 441.0876770019531, 219.27114868164062, 146.72808837890625, 117.77033996582031, 242.1302032470703, 99.4996566772461, 114.99583435058594, 218.43316650390625, 130.68096923828125, 302.8566589355469, 65.96293640136719, 99.7138442993164, 288.33331298828125, 62.55624771118164, 95.89468383789062, 83.42847442626953, 246.21560668945312, 122.11559295654297, 122.27669525146484, 260.1666564941406, 110.49649810791016, 142.92300415039062, 113.67218780517578, 130.62130737304688, 131.79885864257812, 121.53746032714844, 174.32647705078125, 148.086669921875, 121.67925262451172, 133.89720153808594, 137.1377716064453, 142.3141326904297, 124.69952392578125, 129.85687255859375, 42.03095626831055, 41.969940185546875, 40.5953483581543, 38.24845504760742, 28.668846130371094, 45.70606994628906, 38.384552001953125, 26.382015228271484, 27.74530792236328, 24.88882827758789, 21.820493698120117, 33.64678192138672, 21.779388427734375, 23.77460479736328, 21.75609588623047, 32.064598083496094, 20.941606521606445, 18.827241897583008, 18.679697036743164, 18.087247848510742, 69.62647247314453, 16.46963882446289, 20.934038162231445, 15.665606498718262, 30.010255813598633, 81.96968078613281, 44.17984390258789, 18.993743896484375, 14.2196626663208, 14.219005584716797, 26.214160919189453, 31.346582412719727, 31.073110580444336, 38.3902587890625, 26.54414176940918, 93.53347778320312, 62.48457336425781, 42.887413024902344, 206.99974060058594, 45.28080368041992, 76.95359802246094, 182.904296875, 44.33420944213867, 65.77037048339844, 49.767452239990234, 317.00653076171875, 83.6600570678711, 39.394283294677734, 287.84368896484375, 221.7063446044922, 141.3502655029297, 161.62986755371094, 177.5552520751953, 111.8515396118164, 105.3499984741211, 159.1251983642578, 123.4247055053711, 185.71571350097656, 123.48162078857422, 136.87791442871094, 173.77212524414062, 78.29483795166016, 91.91127014160156, 104.75930786132812, 74.40901947021484, 122.24720001220703, 135.25628662109375, 112.78780364990234, 93.30596160888672, 108.88098907470703, 137.8595428466797, 115.12714385986328, 96.96534729003906, 96.237060546875, 94.4668197631836, 90.42465209960938, 41.427085876464844, 31.742156982421875, 53.382179260253906, 25.110164642333984, 23.1042423248291, 21.692546844482422, 21.116918563842773, 22.093814849853516, 24.434816360473633, 19.142406463623047, 19.05367660522461, 15.826476097106934, 17.184019088745117, 13.821077346801758, 13.154617309570312, 19.140451431274414, 11.858264923095703, 14.515873908996582, 19.12070655822754, 19.79554557800293, 11.208646774291992, 11.196525573730469, 15.759903907775879, 11.165010452270508, 10.525443077087402, 11.844698905944824, 27.291898727416992, 10.45200252532959, 12.469965934753418, 9.854464530944824, 25.416818618774414, 18.36568832397461, 107.99810791015625, 48.146236419677734, 15.167680740356445, 25.79690170288086, 28.39680290222168, 52.129425048828125, 39.109004974365234, 53.43753433227539, 70.90505981445312, 84.26734924316406, 165.58920288085938, 183.01968383789062, 79.84716033935547, 154.6665496826172, 66.42511749267578, 46.35023498535156, 150.46929931640625, 41.37286376953125, 49.673179626464844, 73.39604187011719, 133.2668914794922, 133.21737670898438, 99.93948364257812, 49.70652389526367, 125.11978912353516, 70.72160339355469, 73.19246673583984, 80.54623413085938, 92.33466339111328, 78.499755859375, 62.325260162353516, 95.96240234375, 77.7928695678711, 71.92100524902344, 109.82421875, 73.15753936767578, 71.05081939697266, 68.07756042480469, 65.45561218261719, 63.991336822509766, 61.21245193481445, 18.42978286743164, 17.429868698120117, 14.895148277282715, 15.047311782836914, 13.580225944519043, 11.326377868652344, 11.159873962402344, 9.83441162109375, 8.935652732849121, 8.928481101989746, 18.899282455444336, 9.012958526611328, 8.23308277130127, 7.439681053161621, 7.438353061676025, 8.082096099853516, 7.712708950042725, 6.943163871765137, 6.939268112182617, 6.936840057373047, 7.236478805541992, 6.445024490356445, 6.440901279449463, 6.437936782836914, 6.431089878082275, 8.415532112121582, 34.794132232666016, 6.397958278656006, 5.946019649505615, 5.944267749786377, 7.388357162475586, 52.759910583496094, 15.643946647644043, 36.76193618774414, 84.06732940673828, 31.220399856567383, 59.237091064453125, 14.551990509033203, 45.94580841064453, 27.673011779785156, 13.766057968139648, 23.81568145751953, 44.898582458496094, 25.278749465942383, 19.78826904296875, 76.08744812011719, 11.892123222351074, 40.01884078979492, 46.45555114746094, 65.83931732177734, 84.15385437011719, 23.357372283935547, 80.599609375, 48.37336730957031, 35.31317901611328, 39.61531448364258, 47.147804260253906, 46.9440803527832, 28.327056884765625, 48.27543258666992, 37.59587860107422, 35.45008087158203, 24.937490463256836, 29.10690689086914, 27.2191162109375, 27.69222640991211, 26.825782775878906, 27.39418601989746, 25.512832641601562, 19.520883560180664, 15.740466117858887, 11.802599906921387, 12.00153923034668, 7.838012218475342, 7.309489727020264, 10.098942756652832, 58.45075988769531, 6.1623687744140625, 5.868042469024658, 5.863382339477539, 5.859999179840088, 6.1199517250061035, 5.7614545822143555, 4.972497940063477, 4.6024861335754395, 5.864952087402344, 6.220973491668701, 39.75865173339844, 3.889092206954956, 3.8261353969573975, 3.500685453414917, 3.495074987411499, 3.453693151473999, 3.4438986778259277, 3.4365715980529785, 10.124977111816406, 12.109729766845703, 3.104227066040039, 5.407182216644287, 11.480094909667969, 10.651484489440918, 38.739891052246094, 4.9724650382995605, 8.37142276763916, 5.390007019042969, 13.484853744506836, 54.96751403808594, 34.897491455078125, 31.850833892822266, 41.812782287597656, 71.43911743164062, 24.138248443603516, 24.11141014099121, 36.571231842041016, 27.264015197753906, 17.670740127563477, 21.397781372070312, 16.22732925415039, 28.480487823486328, 16.7744083404541, 31.601716995239258, 17.396787643432617, 21.211523056030273, 25.10953712463379, 20.030874252319336, 15.54741096496582, 20.817214965820312, 23.94518280029297, 22.28081703186035, 17.543357849121094, 19.602474212646484, 17.76100730895996, 16.173126220703125, 13.345634460449219, 6.401670455932617, 6.397401809692383, 5.324660778045654, 4.25234317779541, 4.1519012451171875, 3.7070271968841553, 4.492337226867676, 6.518313407897949, 3.9736106395721436, 6.8360595703125, 3.438580274581909, 3.3868517875671387, 3.1138556003570557, 2.9119434356689453, 2.9117236137390137, 4.432435035705566, 2.8935866355895996, 8.513980865478516, 7.0804123878479, 3.0308773517608643, 14.332353591918945, 2.641918659210205, 2.640413284301758, 2.6366641521453857, 5.559959888458252, 2.3730900287628174, 31.56734848022461, 2.1042518615722656, 2.1034064292907715, 3.123927116394043, 6.602177143096924, 8.961726188659668, 3.7343719005584717, 20.871990203857422, 5.605659484863281, 20.05839729309082, 7.698587894439697, 13.303889274597168, 4.451730728149414, 15.648680686950684, 11.976640701293945, 8.628824234008789, 15.048025131225586, 7.007173538208008, 5.2871904373168945, 6.165951251983643, 9.630684852600098, 8.15742015838623, 11.367291450500488, 5.272347450256348, 6.8034586906433105, 6.518519878387451, 5.83904504776001, 5.826862335205078, 5.855615139007568, 3.392444133758545, 2.822619676589966, 2.3259968757629395, 0.9097089171409607, 0.909890353679657, 1.3165793418884277, 0.7675824165344238, 0.6973935961723328, 0.6970089673995972, 0.9798198938369751, 1.6870148181915283, 1.0941184759140015, 0.5553109645843506, 1.1147513389587402, 0.4847274124622345, 0.41383618116378784, 0.41380441188812256, 0.6082162857055664, 0.4137895703315735, 0.3431923985481262, 0.3430885374546051, 0.34303992986679077, 1.2927892208099365, 0.3427751958370209, 0.3429104685783386, 0.2725556194782257, 0.2725079655647278, 0.27250736951828003, 0.27241912484169006, 0.2723836898803711, 0.7543327212333679, 3.775336742401123, 1.2212157249450684, 0.4013940393924713, 1.085747241973877, 1.397646188735962, 0.9273465275764465, 1.3239405155181885, 0.933907687664032, 0.680526077747345, 0.5102656483650208, 0.744688093662262, 0.9568114876747131, 0.8870348930358887, 0.5791761875152588, 1.0686182975769043, 0.7306272983551025, 0.6100077629089355], \"Total\": [233.0, 1165.0, 273.0, 257.0, 519.0, 70.0, 87.0, 638.0, 132.0, 400.0, 93.0, 410.0, 441.0, 325.0, 274.0, 168.0, 834.0, 124.0, 386.0, 142.0, 184.0, 189.0, 75.0, 501.0, 127.0, 1023.0, 168.0, 145.0, 406.0, 215.0, 70.7215347290039, 65.54341125488281, 55.89097595214844, 47.27684020996094, 68.48702239990234, 56.03013229370117, 37.793941497802734, 78.77218627929688, 34.30345916748047, 33.42136764526367, 29.962541580200195, 29.090702056884766, 27.357717514038086, 33.249053955078125, 27.30750846862793, 25.601932525634766, 91.31716918945312, 24.739852905273438, 29.72112464904785, 28.892711639404297, 23.87386131286621, 23.856693267822266, 23.86858558654785, 29.86957359313965, 70.2611312866211, 23.005056381225586, 112.84732818603516, 22.136032104492188, 22.111936569213867, 66.1429214477539, 233.86032104492188, 154.37770080566406, 254.82278442382812, 400.5877990722656, 64.79390716552734, 75.1827392578125, 47.2283935546875, 121.09703826904297, 75.21011352539062, 61.312599182128906, 1489.95849609375, 102.97407531738281, 100.43728637695312, 158.4630584716797, 144.66989135742188, 371.097412109375, 189.14276123046875, 78.17224884033203, 148.49166870117188, 731.9966430664062, 409.3133544921875, 1023.2949829101562, 494.7525634765625, 375.8533630371094, 909.3013916015625, 1097.041015625, 564.356689453125, 598.7749633789062, 819.2603759765625, 1173.7032470703125, 1165.8824462890625, 691.0719604492188, 638.6634521484375, 366.0478210449219, 1174.146240234375, 327.4120178222656, 360.1356201171875, 453.5339050292969, 305.0563659667969, 495.8557434082031, 655.8118896484375, 382.83660888671875, 478.90228271484375, 682.1094970703125, 403.2788391113281, 834.5164184570312, 40.644447326660156, 35.82859802246094, 34.24351501464844, 32.65010452270508, 273.6565856933594, 45.07694625854492, 45.18299102783203, 28.648155212402344, 27.054567337036133, 26.25876235961914, 27.037132263183594, 24.65761947631836, 23.865074157714844, 43.75299835205078, 20.66411590576172, 21.455970764160156, 19.86073875427246, 19.071624755859375, 19.069433212280273, 18.26585578918457, 26.155912399291992, 20.575284957885742, 17.474031448364258, 17.474441528320312, 17.46413230895996, 24.987157821655273, 53.08637237548828, 34.811370849609375, 15.88208293914795, 19.031536102294922, 215.2930450439453, 57.74784469604492, 31.39332389831543, 54.05084991455078, 58.22735595703125, 148.79234313964844, 400.26593017578125, 834.5164184570312, 1173.7032470703125, 501.4322509765625, 319.70269775390625, 241.85032653808594, 638.6634521484375, 213.77964782714844, 264.6352844238281, 682.1094970703125, 331.1729431152344, 1165.8824462890625, 124.29566955566406, 234.28846740722656, 1174.146240234375, 117.85941314697266, 230.60142517089844, 186.45809936523438, 1097.041015625, 366.20391845703125, 386.89239501953125, 1489.95849609375, 325.35174560546875, 519.8451538085938, 346.3223571777344, 482.0777587890625, 495.8557434082031, 427.9764404296875, 909.3013916015625, 691.0719604492188, 441.9068298339844, 598.7749633789062, 655.8118896484375, 819.2603759765625, 731.9966430664062, 1023.2949829101562, 45.64054489135742, 45.65508270263672, 44.76007843017578, 42.363399505615234, 31.989864349365234, 51.029510498046875, 43.208343505859375, 29.722278594970703, 31.26215934753418, 28.213348388671875, 25.179527282714844, 38.854331970214844, 25.15304183959961, 27.46095848083496, 25.13479232788086, 37.07668685913086, 24.396764755249023, 22.116588592529297, 22.047691345214844, 21.378190994262695, 83.30622863769531, 19.860471725463867, 25.260730743408203, 19.078882217407227, 36.57792663574219, 100.2270278930664, 54.22193908691406, 23.377004623413086, 17.549898147583008, 17.550628662109375, 32.76864242553711, 39.59716033935547, 39.35727310180664, 49.81361770629883, 33.78547286987305, 145.4134521484375, 91.1505355834961, 59.79029083251953, 406.9850769042969, 64.33114624023438, 125.42989349365234, 408.1737365722656, 64.96660614013672, 113.15991973876953, 78.59486389160156, 1174.146240234375, 179.1078338623047, 57.22637939453125, 1489.95849609375, 1023.2949829101562, 484.65338134765625, 682.1094970703125, 819.2603759765625, 363.60308837890625, 331.1729431152344, 731.9966430664062, 484.9597473144531, 1097.041015625, 496.755126953125, 655.8118896484375, 1165.8824462890625, 211.72450256347656, 306.6417541503906, 427.9764404296875, 193.77206420898438, 691.0719604492188, 909.3013916015625, 598.7749633789062, 360.1356201171875, 564.356689453125, 1173.7032470703125, 834.5164184570312, 495.8557434082031, 519.8451538085938, 494.7525634765625, 378.9174499511719, 45.155460357666016, 35.22108840942383, 60.45440673828125, 28.56321907043457, 26.563488006591797, 25.225984573364258, 24.561792373657227, 25.849416732788086, 28.71537208557129, 22.56478500366211, 22.56810760498047, 19.22946548461914, 21.350421905517578, 17.235660552978516, 16.568159103393555, 24.148157119750977, 15.229188919067383, 18.649465560913086, 24.80670166015625, 25.700695037841797, 14.558573722839355, 14.55982494354248, 20.530925750732422, 14.570439338684082, 13.899582862854004, 15.730621337890625, 36.30046844482422, 13.926345825195312, 16.67946434020996, 13.22311782836914, 35.256561279296875, 26.040821075439453, 189.3320770263672, 79.66123962402344, 21.181819915771484, 42.44234085083008, 48.97806167602539, 109.82481384277344, 81.24523162841797, 127.62940979003906, 209.28564453125, 280.8269348144531, 834.5164184570312, 1023.2949829101562, 293.79998779296875, 909.3013916015625, 232.25587463378906, 124.75614166259766, 1173.7032470703125, 103.93782806396484, 149.84039306640625, 331.46783447265625, 1097.041015625, 1165.8824462890625, 655.8118896484375, 153.68353271484375, 1174.146240234375, 336.3471374511719, 363.60308837890625, 482.0777587890625, 691.0719604492188, 484.9597473144531, 272.73089599609375, 819.2603759765625, 501.4322509765625, 427.9764404296875, 1489.95849609375, 453.5339050292969, 484.65338134765625, 478.90228271484375, 403.2788391113281, 418.2349548339844, 410.9106140136719, 22.06015968322754, 21.02238655090332, 18.527454376220703, 19.26460075378418, 17.7304630279541, 15.06922435760498, 15.168603897094727, 13.547106742858887, 12.459543228149414, 12.485078811645508, 27.59880828857422, 13.189560890197754, 12.098612785339355, 10.953096389770508, 10.967869758605957, 12.13127326965332, 11.607254981994629, 10.449655532836914, 10.446687698364258, 10.448556900024414, 11.086832046508789, 9.945817947387695, 9.944056510925293, 9.947174072265625, 9.963907241821289, 13.044133186340332, 54.18246841430664, 9.973774909973145, 9.443668365478516, 9.443467140197754, 11.783354759216309, 94.33760833740234, 28.49744987487793, 87.01545715332031, 257.2885437011719, 73.6855239868164, 168.31973266601562, 28.326059341430664, 127.1612548828125, 67.22468566894531, 26.850961685180664, 58.55970001220703, 145.60032653808594, 67.67784881591797, 47.09100341796875, 410.9106140136719, 22.622474670410156, 180.11537170410156, 254.72866821289062, 638.6634521484375, 1165.8824462890625, 87.37748718261719, 1097.041015625, 494.7525634765625, 293.79998779296875, 441.9068298339844, 819.2603759765625, 909.3013916015625, 193.77206420898438, 1174.146240234375, 564.356689453125, 496.755126953125, 169.92564392089844, 478.90228271484375, 484.9597473144531, 691.0719604492188, 682.1094970703125, 1489.95849609375, 408.1737365722656, 23.747243881225586, 19.554105758666992, 15.538546562194824, 15.954591751098633, 11.540335655212402, 11.270729064941406, 15.625921249389648, 93.90267181396484, 9.938555717468262, 9.534017562866211, 9.540345191955566, 9.541479110717773, 10.076496124267578, 9.536908149719238, 8.738870620727539, 8.427448272705078, 10.813915252685547, 11.708880424499512, 75.48242950439453, 7.536323547363281, 7.6090874671936035, 7.125524520874023, 7.134240627288818, 7.122318744659424, 7.128279209136963, 7.203172206878662, 21.442455291748047, 26.128198623657227, 6.726742744445801, 11.724178314208984, 25.671918869018555, 26.022653579711914, 124.63273620605469, 11.122824668884277, 24.791444778442383, 13.321359634399414, 53.53384780883789, 519.8451538085938, 274.5435485839844, 257.2885437011719, 441.9068298339844, 1165.8824462890625, 168.51318359375, 168.31973266601562, 386.89239501953125, 292.0010070800781, 117.10182189941406, 204.75131225585938, 109.895751953125, 496.755126953125, 136.24981689453125, 731.9966430664062, 157.451416015625, 325.35174560546875, 655.8118896484375, 305.0563659667969, 120.078857421875, 501.4322509765625, 1174.146240234375, 819.2603759765625, 279.0097961425781, 1023.2949829101562, 909.3013916015625, 1097.041015625, 17.374095916748047, 10.226821899414062, 10.22836971282959, 9.13489818572998, 8.040245056152344, 8.27426528930664, 7.503670692443848, 9.179532051086426, 13.440201759338379, 8.322127342224121, 14.353509902954102, 7.229689598083496, 7.363480091094971, 7.099609375, 6.671756744384766, 6.674102783203125, 10.248364448547363, 6.711475849151611, 19.863197326660156, 16.77437400817871, 7.2830305099487305, 34.67469024658203, 6.401974678039551, 6.399477481842041, 6.407688617706299, 13.953969955444336, 6.126201629638672, 87.14323425292969, 5.854192733764648, 5.85706901550293, 8.808101654052734, 19.665817260742188, 31.211442947387695, 10.929905891418457, 132.93992614746094, 21.46772003173828, 233.86032104492188, 47.021671295166016, 142.4160614013672, 16.40128517150879, 325.4890441894531, 184.8996124267578, 87.37748718261719, 400.26593017578125, 58.058631896972656, 27.709787368774414, 45.663238525390625, 336.3471374511719, 198.9343719482422, 1174.146240234375, 29.183107376098633, 195.41976928710938, 371.097412109375, 184.35716247558594, 245.54135131835938, 731.9966430664062, 7.511183261871338, 6.920387268066406, 7.994391918182373, 4.867552280426025, 4.869908809661865, 7.484256267547607, 4.721133232116699, 4.638817310333252, 4.644497871398926, 7.068500518798828, 13.368843078613281, 8.769201278686523, 4.492266654968262, 9.551162719726562, 4.412615776062012, 4.336733818054199, 4.336934566497803, 6.498591899871826, 5.000957489013672, 4.258847713470459, 4.258828163146973, 4.2610182762146, 16.928625106811523, 5.01276159286499, 5.085238933563232, 4.181179046630859, 4.180911540985107, 4.181029796600342, 4.18192720413208, 4.181856155395508, 11.857321739196777, 70.2611312866211, 24.847261428833008, 6.883960247039795, 28.315210342407227, 85.03849792480469, 63.428890228271484, 291.2559509277344, 98.15943908691406, 36.97760772705078, 15.741545677185059, 72.56367492675781, 325.4890441894531, 274.5435485839844, 26.850961685180664, 1023.2949829101562, 371.097412109375, 75.32986450195312], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.910900115966797, -6.989200115203857, -7.1616997718811035, -7.338799953460693, -6.978099822998047, -7.18179988861084, -7.5756001472473145, -6.843500137329102, -7.683199882507324, -7.710999965667725, -7.832799911499023, -7.866300106048584, -7.934599876403809, -7.73960018157959, -7.939700126647949, -8.009900093078613, -6.739500045776367, -8.049200057983398, -7.86899995803833, -7.898399829864502, -8.09000015258789, -8.090999603271484, -8.090499877929688, -7.868199825286865, -7.014500141143799, -8.133000373840332, -6.545300006866455, -8.177399635314941, -8.180100440979004, -7.086900234222412, -5.8333001136779785, -6.248700141906738, -5.826900005340576, -5.397299766540527, -7.140200138092041, -7.003499984741211, -7.462299823760986, -6.615099906921387, -7.048600196838379, -7.232999801635742, -4.441299915313721, -6.777200222015381, -6.809599876403809, -6.4207000732421875, -6.502900123596191, -5.71560001373291, -6.282800197601318, -7.029600143432617, -6.5019001960754395, -5.25029993057251, -5.7241997718811035, -5.023900032043457, -5.607699871063232, -5.819900035858154, -5.183300018310547, -5.048299789428711, -5.538599967956543, -5.521200180053711, -5.313600063323975, -5.083399772644043, -5.129000186920166, -5.487599849700928, -5.54040002822876, -5.9105000495910645, -5.232900142669678, -6.011300086975098, -5.96019983291626, -5.827600002288818, -6.059299945831299, -5.812600135803223, -5.666600227355957, -5.964000225067139, -5.866499900817871, -5.763400077819824, -5.9633002281188965, -5.918799877166748, -7.045499801635742, -7.183899879455566, -7.232100009918213, -7.28439998626709, -5.158999919891357, -6.962900161743164, -6.967800140380859, -7.43779993057251, -7.4980998039245605, -7.528600215911865, -7.503799915313721, -7.603400230407715, -7.638800144195557, -7.053599834442139, -7.813300132751465, -7.7758002281188965, -7.862800121307373, -7.904900074005127, -7.908400058746338, -7.960100173950195, -7.604000091552734, -7.846700191497803, -8.014300346374512, -8.015899658203125, -8.01830005645752, -7.6620001792907715, -6.911200046539307, -7.335400104522705, -8.12660026550293, -7.954800128936768, -5.55109977722168, -6.912700176239014, -7.490200042724609, -7.044400215148926, -6.989200115203857, -6.211900234222412, -5.406499862670898, -4.805200099945068, -4.57450008392334, -5.273499965667725, -5.67519998550415, -5.894999980926514, -5.174300193786621, -6.063600063323975, -5.918900012969971, -5.277299880981445, -5.790999889373779, -4.950500011444092, -6.474699974060059, -6.061500072479248, -4.99970006942749, -6.527699947357178, -6.100500106811523, -6.239799976348877, -5.157599925994873, -5.858799934387207, -5.857500076293945, -5.102499961853027, -5.958799839019775, -5.701499938964844, -5.930500030517578, -5.791500091552734, -5.78249979019165, -5.86359977722168, -5.502900123596191, -5.665999889373779, -5.862400054931641, -5.76669979095459, -5.742800235748291, -5.705699920654297, -5.837900161743164, -5.797399997711182, -6.855299949645996, -6.8566999435424805, -6.889999866485596, -6.9496002197265625, -7.2378997802734375, -6.771399974822998, -6.946000099182129, -7.321000099182129, -7.270599842071533, -7.379199981689453, -7.510799884796143, -7.0777997970581055, -7.512700080871582, -7.425099849700928, -7.513800144195557, -7.125899791717529, -7.5518999099731445, -7.658400058746338, -7.666200160980225, -7.698500156402588, -6.350500106811523, -7.792200088500977, -7.552299976348877, -7.842199802398682, -7.1921000480651855, -6.187300205230713, -6.8053998947143555, -7.649600028991699, -7.939000129699707, -7.9390997886657715, -7.327400207519531, -7.148600101470947, -7.157299995422363, -6.945899963378906, -7.314899921417236, -6.055300235748291, -6.458700180053711, -6.835100173950195, -5.261000156402588, -6.780799865722656, -6.250500202178955, -5.384699821472168, -6.8018999099731445, -6.40749979019165, -6.686299800872803, -4.834700107574463, -6.166900157928467, -6.920000076293945, -4.931300163269043, -5.192299842834473, -5.642399787902832, -5.508399963378906, -5.414400100708008, -5.876500129699707, -5.936399936676025, -5.52400016784668, -5.7779998779296875, -5.369500160217285, -5.777599811553955, -5.674600124359131, -5.4359002113342285, -6.2332000732421875, -6.072800159454346, -5.941999912261963, -6.28410005569458, -5.787600040435791, -5.686500072479248, -5.868199825286865, -6.057799816131592, -5.90339994430542, -5.667399883270264, -5.847599983215332, -6.0192999839782715, -6.026899814605713, -6.045400142669678, -6.089200019836426, -6.472599983215332, -6.738900184631348, -6.219099998474121, -6.973299980163574, -7.05649995803833, -7.11959981918335, -7.146500110626221, -7.101200103759766, -7.000500202178955, -7.24459981918335, -7.249300003051758, -7.434899806976318, -7.35260009765625, -7.570300102233887, -7.619800090789795, -7.244699954986572, -7.723499774932861, -7.521299839019775, -7.245800018310547, -7.211100101470947, -7.779900074005127, -7.780900001525879, -7.4390997886657715, -7.78380012512207, -7.842700004577637, -7.724699974060059, -6.889999866485596, -7.849699974060059, -7.6732001304626465, -7.908599853515625, -6.961100101470947, -7.286099910736084, -5.514400005340576, -6.322299957275391, -7.477399826049805, -6.946300029754639, -6.850299835205078, -6.242800235748291, -6.530200004577637, -6.2179999351501465, -5.935200214385986, -5.762499809265137, -5.086999893188477, -4.9868998527526855, -5.816400051116943, -5.155300140380859, -6.000500202178955, -6.360300064086914, -5.182799816131592, -6.473899841308594, -6.291100025177002, -5.900700092315674, -5.304200172424316, -5.304599761962891, -5.5920000076293945, -6.29040002822876, -5.367300033569336, -5.93779993057251, -5.903500080108643, -5.807700157165527, -5.67110013961792, -5.833399772644043, -6.064199924468994, -5.632599830627441, -5.84250020980835, -5.921000003814697, -5.497700214385986, -5.903900146484375, -5.93310022354126, -5.975900173187256, -6.015200138092041, -6.037799835205078, -6.082200050354004, -6.676700115203857, -6.732500076293945, -6.889599800109863, -6.879499912261963, -6.98199987411499, -7.16349983215332, -7.178299903869629, -7.304800033569336, -7.400599956512451, -7.401400089263916, -6.651500225067139, -7.392000198364258, -7.482500076293945, -7.583799839019775, -7.584000110626221, -7.500999927520752, -7.547800064086914, -7.652900218963623, -7.653500080108643, -7.653800010681152, -7.611499786376953, -7.72730016708374, -7.728000164031982, -7.728400230407715, -7.729499816894531, -7.460599899291992, -6.041200160980225, -7.7347002029418945, -7.8078999519348145, -7.808199882507324, -7.590700149536133, -5.624899864196777, -6.84060001373291, -5.986199855804443, -5.158999919891357, -6.149600028991699, -5.509099960327148, -6.912899971008301, -5.763199806213379, -6.270199775695801, -6.968400001525879, -6.420300006866455, -5.786200046539307, -6.3607001304626465, -6.605599880218506, -5.258800029754639, -7.114799976348877, -5.901299953460693, -5.752200126647949, -5.40339994430542, -5.1579999923706055, -6.439700126647949, -5.201200008392334, -5.711699962615967, -6.026400089263916, -5.911399841308594, -5.737400054931641, -5.741700172424316, -6.246799945831299, -5.713699817657471, -5.963799953460693, -6.022500038146973, -6.374300003051758, -6.219699859619141, -6.2866997718811035, -6.269499778747559, -6.301300048828125, -6.280300140380859, -6.351500034332275, -6.158899784088135, -6.374199867248535, -6.662099838256836, -6.645400047302246, -7.071400165557861, -7.141200065612793, -6.817999839782715, -5.06220006942749, -7.3119001388549805, -7.360899925231934, -7.361700057983398, -7.362199783325195, -7.31879997253418, -7.379199981689453, -7.526500225067139, -7.603799819946289, -7.361400127410889, -7.302499771118164, -5.4475998878479, -7.772200107574463, -7.78849983215332, -7.877399921417236, -7.879000186920166, -7.890999794006348, -7.893799781799316, -7.895899772644043, -6.815400123596191, -6.63640022277832, -7.997600078582764, -7.442699909210205, -6.689799785614014, -6.764699935913086, -5.473499774932861, -7.526500225067139, -7.0055999755859375, -7.445799827575684, -6.528800010681152, -5.123700141906738, -5.578000068664551, -5.669300079345703, -5.397200107574463, -4.861599922180176, -5.946599960327148, -5.947700023651123, -5.531099796295166, -5.82480001449585, -6.258500099182129, -6.0671000480651855, -6.343699932098389, -5.781199932098389, -6.310500144958496, -5.677199840545654, -6.274099826812744, -6.075900077819824, -5.907100200653076, -6.1331000328063965, -6.386499881744385, -6.094600200653076, -5.954599857330322, -6.026700019836426, -6.265699863433838, -6.154699802398682, -6.253399848937988, -6.3470001220703125, -5.935200214385986, -6.6697998046875, -6.670499801635742, -6.854000091552734, -7.07889986038208, -7.102799892425537, -7.216100215911865, -7.02400016784668, -6.651800155639648, -7.146699905395508, -6.6041998863220215, -7.291299819946289, -7.30649995803833, -7.390500068664551, -7.457600116729736, -7.457600116729736, -7.037399768829346, -7.463900089263916, -6.384699821472168, -6.568999767303467, -7.417500019073486, -5.863900184631348, -7.554900169372559, -7.5553998947143555, -7.5569000244140625, -6.810800075531006, -7.662199974060059, -5.0742998123168945, -7.782400131225586, -7.782800197601318, -7.38730001449585, -6.638999938964844, -6.333399772644043, -7.208799839019775, -5.48799991607666, -6.802599906921387, -5.527699947357178, -6.485300064086914, -5.938300132751465, -7.033100128173828, -5.776000022888184, -6.043399810791016, -6.371300220489502, -5.815100193023682, -6.579400062561035, -6.861100196838379, -6.707300186157227, -6.26140022277832, -6.4274001121521, -6.095600128173828, -6.863900184631348, -6.60890007019043, -6.651700019836426, -6.7617998123168945, -6.763899803161621, -6.758999824523926, -5.692500114440918, -5.876399993896484, -6.069900035858154, -7.008699893951416, -7.008500099182129, -6.638999938964844, -7.178500175476074, -7.274400234222412, -7.275000095367432, -6.9344000816345215, -6.39109992980957, -6.824100017547607, -7.502299785614014, -6.8053998947143555, -7.638199806213379, -7.796299934387207, -7.79640007019043, -7.411200046539307, -7.79640007019043, -7.983500003814697, -7.983799934387207, -7.98390007019043, -6.657199859619141, -7.9847002029418945, -7.984300136566162, -8.213899612426758, -8.214099884033203, -8.214099884033203, -8.214400291442871, -8.214599609375, -7.195899963378906, -5.5854997634887695, -6.714200019836426, -7.8267998695373535, -6.8317999839782715, -6.57919979095459, -6.989500045776367, -6.633399963378906, -6.982399940490723, -7.298900127410889, -7.5868000984191895, -7.208799839019775, -6.958199977874756, -7.033899784088135, -7.46019983291626, -6.847700119018555, -7.22790002822876, -7.408299922943115]}};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el106241407142093200164207503242\", ldavis_el106241407142093200164207503242_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el106241407142093200164207503242\", ldavis_el106241407142093200164207503242_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el106241407142093200164207503242\", ldavis_el106241407142093200164207503242_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=            Freq  cluster  topics         x         y\n",
       "topic                                                \n",
       "5      32.598530        1       1 -0.099315  0.031513\n",
       "4      20.686474        1       2 -0.076826 -0.033969\n",
       "7      19.285721        1       3 -0.061428  0.015668\n",
       "3      12.964823        1       4 -0.039307 -0.023796\n",
       "0       7.073448        1       5  0.017009  0.040609\n",
       "1       4.464208        1       6  0.033080 -0.047669\n",
       "2       2.440185        1       7  0.096261  0.025379\n",
       "6       0.486616        1       8  0.130526 -0.007735, topic_info=      Category         Freq            Term        Total  loglift  logprob\n",
       "6839   Default   233.000000          neuron   233.000000  30.0000  30.0000\n",
       "2636   Default  1165.000000       algorithm  1165.000000  29.0000  29.0000\n",
       "8238   Default   273.000000          policy   273.000000  28.0000  28.0000\n",
       "8602   Default   257.000000         cluster   257.000000  27.0000  27.0000\n",
       "8152   Default   519.000000          sample   519.000000  26.0000  26.0000\n",
       "12740  Default    70.000000         circuit    70.000000  25.0000  25.0000\n",
       "10725  Default    87.000000           spike    87.000000  24.0000  24.0000\n",
       "6741   Default   638.000000           state   638.000000  23.0000  23.0000\n",
       "6399   Default   132.000000         control   132.000000  22.0000  22.0000\n",
       "1047   Default   400.000000         optimal   400.000000  21.0000  21.0000\n",
       "6815   Default    93.000000        subspace    93.000000  20.0000  20.0000\n",
       "11491  Default   410.000000            node   410.000000  19.0000  19.0000\n",
       "9421   Default   441.000000           point   441.000000  18.0000  18.0000\n",
       "2992   Default   325.000000          system   325.000000  17.0000  17.0000\n",
       "184    Default   274.000000         machine   274.000000  16.0000  16.0000\n",
       "2542   Default   168.000000      clustering   168.000000  15.0000  15.0000\n",
       "6767   Default   834.000000         problem   834.000000  14.0000  14.0000\n",
       "11084  Default   124.000000         mixture   124.000000  13.0000  13.0000\n",
       "5265   Default   386.000000             log   386.000000  12.0000  12.0000\n",
       "7118   Default   142.000000         dynamic   142.000000  11.0000  11.0000\n",
       "10489  Default   184.000000           noise   184.000000  10.0000  10.0000\n",
       "13780  Default   189.000000            view   189.000000   9.0000   9.0000\n",
       "12274  Default    75.000000       estimator    75.000000   8.0000   8.0000\n",
       "2936   Default   501.000000          matrix   501.000000   7.0000   7.0000\n",
       "6308   Default   127.000000            cell   127.000000   6.0000   6.0000\n",
       "1915   Default  1023.000000           learn  1023.000000   5.0000   5.0000\n",
       "8835   Default   168.000000          vertex   168.000000   4.0000   4.0000\n",
       "11113  Default   145.000000       detection   145.000000   3.0000   3.0000\n",
       "181    Default   406.000000         feature   406.000000   2.0000   2.0000\n",
       "7380   Default   215.000000        gradient   215.000000   1.0000   1.0000\n",
       "...        ...          ...             ...          ...      ...      ...\n",
       "11119   Topic8     0.413790   correlational     5.000957   2.8334  -7.7964\n",
       "8446    Topic8     0.343192            shon     4.258848   2.8070  -7.9835\n",
       "469     Topic8     0.343089        figueroa     4.258828   2.8067  -7.9838\n",
       "11372   Topic8     0.343040             hsu     4.261018   2.8060  -7.9839\n",
       "2255    Topic8     1.292789          analog    16.928625   2.7532  -6.6572\n",
       "3575    Topic8     0.342775             cmo     5.012762   2.6428  -7.9847\n",
       "6587    Topic8     0.342910       configure     5.085239   2.6288  -7.9843\n",
       "9711    Topic8     0.272556   functionality     4.181179   2.5949  -8.2139\n",
       "11836   Topic8     0.272508        designer     4.180912   2.5948  -8.2141\n",
       "799     Topic8     0.272507            fpga     4.181030   2.5948  -8.2141\n",
       "3941    Topic8     0.272419        nfet_plb     4.181927   2.5943  -8.2144\n",
       "9999    Topic8     0.272384             dac     4.181856   2.5942  -8.2146\n",
       "2421    Topic8     0.754333        comprise    11.857322   2.5706  -7.1959\n",
       "12740   Topic8     3.775337         circuit    70.261131   2.4017  -5.5855\n",
       "1441    Topic8     1.221216       prototype    24.847261   2.3125  -6.7142\n",
       "2551    Topic8     0.401394          custom     6.883960   2.4834  -7.8268\n",
       "1446    Topic8     1.085747          enable    28.315210   2.0643  -6.8318\n",
       "12475   Topic8     1.397646          design    85.038498   1.2171  -6.5792\n",
       "9837    Topic8     0.927347       implement    63.428890   1.1001  -6.9895\n",
       "5054    Topic8     1.323941        learning   291.255951  -0.0681  -6.6334\n",
       "938     Topic8     0.933908         current    98.159439   0.6705  -6.9824\n",
       "3163    Topic8     0.680526   configuration    36.977608   1.3302  -7.2989\n",
       "13768   Topic8     0.510266    differential    15.741546   1.8963  -7.5868\n",
       "7578    Topic8     0.744688    architecture    72.563675   0.7462  -7.2088\n",
       "2992    Topic8     0.956811          system   325.489044  -0.5040  -6.9582\n",
       "184     Topic8     0.887035         machine   274.543549  -0.4095  -7.0339\n",
       "2313    Topic8     0.579176      adaptation    26.850962   1.4890  -7.4602\n",
       "1915    Topic8     1.068618           learn  1023.294983  -1.5390  -6.8477\n",
       "2438    Topic8     0.730627           input   371.097412  -0.9049  -7.2279\n",
       "3990    Topic8     0.610008  implementation    75.329865   0.5093  -7.4083\n",
       "\n",
       "[564 rows x 6 columns], token_table=       Topic      Freq        Term\n",
       "term                              \n",
       "6863       1  0.870451      absorb\n",
       "6863       2  0.066958      absorb\n",
       "6863       3  0.033479      absorb\n",
       "6863       4  0.033479      absorb\n",
       "1862       1  0.345728      action\n",
       "1862       2  0.426824      action\n",
       "1862       3  0.132316      action\n",
       "1862       4  0.008536      action\n",
       "1862       5  0.085365      action\n",
       "2313       1  0.223456  adaptation\n",
       "2313       2  0.037243  adaptation\n",
       "2313       3  0.037243  adaptation\n",
       "2313       4  0.148970  adaptation\n",
       "2313       5  0.521397  adaptation\n",
       "2313       8  0.037243  adaptation\n",
       "4607       1  0.024604        advi\n",
       "4607       2  0.910333        advi\n",
       "4607       3  0.024604        advi\n",
       "4607       4  0.024604        advi\n",
       "8151       1  0.780935       agent\n",
       "8151       2  0.141275       agent\n",
       "8151       3  0.003924       agent\n",
       "8151       4  0.007849       agent\n",
       "8151       5  0.062789       agent\n",
       "12407      1  0.052440         alg\n",
       "12407      2  0.839039         alg\n",
       "12407      3  0.052440         alg\n",
       "12407      4  0.052440         alg\n",
       "2636       1  0.342230   algorithm\n",
       "2636       2  0.259889   algorithm\n",
       "...      ...       ...         ...\n",
       "13316      7  0.748240         vor\n",
       "6742       1  0.018443     wavelet\n",
       "6742       2  0.129099     wavelet\n",
       "6742       3  0.811480     wavelet\n",
       "6742       4  0.018443     wavelet\n",
       "1091       1  0.065663     webpage\n",
       "1091       2  0.065663     webpage\n",
       "1091       3  0.065663     webpage\n",
       "1091       4  0.787961     webpage\n",
       "7028       1  0.483151      weight\n",
       "7028       2  0.088855      weight\n",
       "7028       3  0.258236      weight\n",
       "7028       4  0.086079      weight\n",
       "7028       5  0.055535      weight\n",
       "7028       6  0.019437      weight\n",
       "7028       7  0.008330      weight\n",
       "4828       1  0.182193          xi\n",
       "4828       2  0.260275          xi\n",
       "4828       3  0.117124          xi\n",
       "4828       4  0.325344          xi\n",
       "4828       5  0.071576          xi\n",
       "4828       6  0.039041          xi\n",
       "7748       1  0.041411         xji\n",
       "7748       2  0.082822         xji\n",
       "7748       3  0.041411         xji\n",
       "7748       4  0.786810         xji\n",
       "18         1  0.045215         xtk\n",
       "18         2  0.045215         xtk\n",
       "18         3  0.859084         xtk\n",
       "18         4  0.045215         xtk\n",
       "\n",
       "[2314 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[6, 5, 8, 4, 1, 2, 3, 7])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis.gensim\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
